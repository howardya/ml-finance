{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "volatility-forecast.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHDNQiYRo4uQQ4fSbqHF1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/howardya/ml-finance/blob/main/volatility/volatility_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG7MzqW1w_DO"
      },
      "source": [
        "# Summary\n",
        "\n",
        "US Total Equity Market Vol (RMSE)\n",
        "\n",
        "| Method | Weekly (2M) |\n",
        "| --- | --- |\n",
        "| 2M Vol | 0.0286387|\n",
        "| 1M Vol | 0.0277460|\n",
        "|4M Vol|0.0296685|\n",
        "| 2M Halflife | 0.0274711|\n",
        "| 1M Halflife | 0.0272838|\n",
        "|4M Halflife|0.0273250|\n",
        "|4M NN-1 Unnormalized|0.0586515|\n",
        "|4M NN-256-128-1 Unnormalized|0.0265297|\n",
        "|4M NN-256-128-1 Unnormalized Relu|0.0272581|\n",
        "|4M NN-1|0.0319316|\n",
        "|4M NN-256-128-1|0.0236697|\n",
        "|4M NN-256-128-1 Relu|0.0234757|\n",
        "|4M NN-256-D20-128-D20-1 Relu|0.0239659|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aga31kk98GX_"
      },
      "source": [
        "# Volatility Forecast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Isf9Bj7-Jt"
      },
      "source": [
        "import pandas as pd\n",
        "import pandas_datareader as pdr\n",
        "import pandas_datareader.data as web\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9D2BYoD9A7s"
      },
      "source": [
        "Print out packages' version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L02ORe88J55",
        "outputId": "26ef1940-c84b-4c8c-a8bd-1593da92d398"
      },
      "source": [
        "loaded_packages = ['pd', 'pdr', 'np','tf']\n",
        "for pkg in loaded_packages:\n",
        "  exec(f'pkg_version = {pkg}.__version__') # get the package's version to be printed out, stored as pkg_version\n",
        "  print(f'{pkg} version: {pkg_version}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pd version: 1.1.5\n",
            "pdr version: 0.9.0\n",
            "np version: 1.19.5\n",
            "tf version: 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTGXYzft-DLD"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKMof4aB8L6H"
      },
      "source": [
        "start_date = '2000-01-01'\n",
        "end_date = '2021-10-01'\n",
        "fred_tickers = [\n",
        "  'WILL5000IND', # https://fred.stlouisfed.org/series/WILL5000IND Wilshire 5000 Total Market Index\n",
        "  # 'NASDAQ100', # https://fred.stlouisfed.org/series/NASDAQ100 \n",
        "  # 'SP500', # https://fred.stlouisfed.org/series/SP500\n",
        "  # 'DGS10', # https://fred.stlouisfed.org/series/DGS10\n",
        "  # 'DGS2', # https://fred.stlouisfed.org/series/DGS2\n",
        "]\n",
        "data = web.DataReader(fred_tickers, 'fred', start = start_date, end=end_date)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmSUR7sN-xG4",
        "outputId": "64db0fa2-91d5-456e-fa5a-2afa672b5369"
      },
      "source": [
        "print(data.info())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 5675 entries, 2000-01-03 to 2021-10-01\n",
            "Data columns (total 1 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   WILL5000IND  5474 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 88.7 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPrq7eC7DMd1"
      },
      "source": [
        "weekly_data = data.resample('W').last() # get the last weekly trading price, dates are on Sunday\n",
        "weekly_data_returns = np.log1p(weekly_data.pct_change().add_suffix('_Ret')).dropna() # calculate weekly log returns"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI5VSr_8-nBK"
      },
      "source": [
        "Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skhz26pD-o1o"
      },
      "source": [
        "def calculate_error_rmse(pd1, pd2):\n",
        "  return np.sqrt( ((pd1.iloc[:,0].values-pd2.iloc[:,0].values)**2).mean())\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FPy9RlJnNXT"
      },
      "source": [
        "## Calculate Realized Volatility\n",
        "\n",
        "Defined as $\\sum_i x_i^2$ where $x_i$s are the forward weekly returns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f618jJRXDN_U"
      },
      "source": [
        "# Calculate the forward realize volatility\n",
        "forward_window = 8 # in weeks\n",
        "\n",
        "realized_volatility = np.log1p(\n",
        "    weekly_data.pct_change().add_suffix('_Ret')\n",
        "  ).dropna().pow(2).rolling(window = forward_window, min_periods=forward_window).mean().shift(-forward_window).pow(0.5).add_suffix('_Realized_Vol').dropna()\n",
        "\n",
        "training_volatility = realized_volatility[:'2019']\n",
        "training_dates = training_volatility.index\n",
        "\n",
        "validation_volatility = realized_volatility['2020':]\n",
        "validation_dates = validation_volatility.index\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG6kSNNA8Dly"
      },
      "source": [
        "## Method 1: Rolling Vol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsnE4QhcDT0f",
        "outputId": "c1db2d99-8800-42bb-b035-3b9f1609002a"
      },
      "source": [
        "simple_vol = weekly_data_returns.pow(2).rolling(window=forward_window).mean().pow(0.5).loc[validation_dates]\n",
        "print(f'2M Rolling: {calculate_error_rmse(simple_vol, validation_volatility)}')\n",
        "\n",
        "simple_vol = weekly_data_returns.pow(2).rolling(window=int(0.5*forward_window) ).mean().pow(0.5).loc[validation_dates]\n",
        "print(f'1M Rolling: {calculate_error_rmse(simple_vol, validation_volatility)}')\n",
        "\n",
        "simple_vol = weekly_data_returns.pow(2).rolling(window=2*forward_window).mean().pow(0.5).loc[validation_dates]\n",
        "print(f'4M Rolling: {calculate_error_rmse(simple_vol, validation_volatility)}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2M Rolling: 0.028638700230523072\n",
            "1M Rolling: 0.027745986066158797\n",
            "4M Rolling: 0.02966853807756445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8UB7Jn73f2u"
      },
      "source": [
        "## Method 2: Halflife"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5hoZMQVMcuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d95095-8886-4d01-d9ec-9be12de35dd1"
      },
      "source": [
        "predicted_vol = weekly_data_returns.pow(2).ewm(halflife=forward_window).mean().pow(0.5).loc[validation_dates]\n",
        "print(f'2M Halflife: {calculate_error_rmse(predicted_vol, validation_volatility)}')\n",
        "\n",
        "predicted_vol = weekly_data_returns.pow(2).ewm(halflife=int(0.5*forward_window) ).mean().pow(0.5).loc[validation_dates]\n",
        "print(f'1M Halflife: {calculate_error_rmse(predicted_vol, validation_volatility)}')\n",
        "\n",
        "predicted_vol = weekly_data_returns.pow(2).ewm(halflife=2*forward_window).mean().pow(0.5).loc[validation_dates]\n",
        "print(f'4M Halflife: {calculate_error_rmse(predicted_vol, validation_volatility)}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2M Halflife: 0.027471132223528552\n",
            "1M Halflife: 0.027283839126274273\n",
            "4M Halflife: 0.027324973671621823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIv9S0MW3UmT"
      },
      "source": [
        "Dataset Preparation for Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ZsqTHu3UFN"
      },
      "source": [
        "# def window_dataset_returns(series, window_size, batch_size=32,\n",
        "#                    shuffle_buffer=1000):\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "#     dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "#     dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "#     dataset = dataset.shuffle(shuffle_buffer)\n",
        "#     dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "#     dataset = dataset.batch(batch_size).prefetch(1)\n",
        "#     return dataset\n",
        "\n",
        "def window_dataset_x(returns_series, dates, window_size, batch_size=1,shuffle_buffer=1000):\n",
        "  returns_data = returns_series.loc[dates]\n",
        "  dataset_x = tf.data.Dataset.from_tensor_slices(returns_data)\n",
        "  dataset_x = dataset_x.window(window_size, shift=1, drop_remainder=True)\n",
        "  dataset_x = dataset_x.flat_map(lambda window: window.batch(window_size))\n",
        "  dataset = dataset_x.batch(batch_size).prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "def window_dataset_y(target_volatility, window_size, batch_size=1,shuffle_buffer=1000):\n",
        "  dataset_y = tf.data.Dataset.from_tensor_slices(target_volatility[window_size:])\n",
        "  dataset = dataset_y.batch(batch_size).prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "def rolling(a, window):\n",
        "    shape = (a.size - window + 1, window)\n",
        "    strides = (a.itemsize, a.itemsize)\n",
        "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuoJuNmh4dzN"
      },
      "source": [
        "## Method 3: Linear Regression (Without Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhyy5Nh75Zw8"
      },
      "source": [
        "window_size = forward_window\n",
        "batch_size = 32\n",
        "shuffle_buffer=1000\n",
        "\n",
        "train_x = rolling(weekly_data_returns.WILL5000IND_Ret[training_dates].values, window_size)\n",
        "train_y = training_volatility.WILL5000IND_Ret_Realized_Vol.values[window_size-1:][:,None]\n",
        "train_data = np.hstack((train_x,train_y))\n",
        "\n",
        "validation_x = rolling(weekly_data_returns[weekly_data_returns.index <= validation_dates[-1]].WILL5000IND_Ret.values, window_size)[-len(validation_dates):]\n",
        "validation_y = validation_volatility.WILL5000IND_Ret_Realized_Vol.values[:,None]\n",
        "validation_data = np.hstack((validation_x,validation_y))\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "train_dataset = train_dataset.shuffle(shuffle_buffer)\n",
        "train_dataset = train_dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_data)\n",
        "validation_dataset = validation_dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "validation_dataset = validation_dataset.batch(batch_size).prefetch(1)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25rE8kSO5-qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5150c46-e764-4b30-a233-9973bb515984"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(1,input_shape=[window_size])\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "model.fit(train_dataset, epochs=100, validation_data=validation_dataset)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 28/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 29/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 30/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 31/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 32/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 33/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 34/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 35/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 36/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 37/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 38/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 39/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 40/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 41/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 42/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 43/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 44/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 45/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 46/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 47/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 48/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 49/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 50/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 51/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 52/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 53/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 54/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 55/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 56/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 57/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 58/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 59/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 60/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 61/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 62/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 63/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 64/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 65/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 66/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 67/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 68/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 69/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 70/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 71/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 72/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 73/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 74/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 75/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 76/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 77/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 78/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 79/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 80/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 81/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 82/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 83/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 84/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 85/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 86/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 87/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 88/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 89/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 90/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 91/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 92/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 93/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 94/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 95/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 96/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 97/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 98/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 99/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0034 - val_mse: 0.0034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89abed34d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huFEivcR8n6V",
        "outputId": "c16c1b7f-b878-4359-d7b6-dd1185b000ee"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction), validation_volatility)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05865153412409621"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2X0EgHVAc78",
        "outputId": "ec2f827d-d3bf-4f0b-c1dc-6ff7607ff27e"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, input_shape=[window_size]),\n",
        "  tf.keras.layers.Dense(128),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "model.fit(train_dataset, epochs=100, validation_data=validation_dataset)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 6.6522e-04 - mse: 6.6522e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 6.3620e-04 - mse: 6.3620e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 6.0685e-04 - mse: 6.0685e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 5.7936e-04 - mse: 5.7936e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 5.5374e-04 - mse: 5.5374e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 5.2990e-04 - mse: 5.2990e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 5.0787e-04 - mse: 5.0787e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.8730e-04 - mse: 4.8730e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.6825e-04 - mse: 4.6825e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.5056e-04 - mse: 4.5056e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.3394e-04 - mse: 4.3394e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.1855e-04 - mse: 4.1855e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.0422e-04 - mse: 4.0422e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.9093e-04 - mse: 3.9093e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.7859e-04 - mse: 3.7859e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.6700e-04 - mse: 3.6700e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.5623e-04 - mse: 3.5623e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.4634e-04 - mse: 3.4634e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.3706e-04 - mse: 3.3706e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.2852e-04 - mse: 3.2852e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.2054e-04 - mse: 3.2054e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.1309e-04 - mse: 3.1309e-04 - val_loss: 9.9371e-04 - val_mse: 9.9371e-04\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.0611e-04 - mse: 3.0611e-04 - val_loss: 9.7960e-04 - val_mse: 9.7960e-04\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.9963e-04 - mse: 2.9963e-04 - val_loss: 9.6639e-04 - val_mse: 9.6639e-04\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.9353e-04 - mse: 2.9353e-04 - val_loss: 9.5359e-04 - val_mse: 9.5359e-04\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8789e-04 - mse: 2.8789e-04 - val_loss: 9.4141e-04 - val_mse: 9.4141e-04\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8270e-04 - mse: 2.8270e-04 - val_loss: 9.3020e-04 - val_mse: 9.3020e-04\n",
            "Epoch 28/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7787e-04 - mse: 2.7787e-04 - val_loss: 9.1970e-04 - val_mse: 9.1970e-04\n",
            "Epoch 29/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7343e-04 - mse: 2.7343e-04 - val_loss: 9.0970e-04 - val_mse: 9.0970e-04\n",
            "Epoch 30/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6923e-04 - mse: 2.6923e-04 - val_loss: 8.9982e-04 - val_mse: 8.9982e-04\n",
            "Epoch 31/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6527e-04 - mse: 2.6527e-04 - val_loss: 8.9080e-04 - val_mse: 8.9080e-04\n",
            "Epoch 32/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6166e-04 - mse: 2.6166e-04 - val_loss: 8.8171e-04 - val_mse: 8.8171e-04\n",
            "Epoch 33/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5826e-04 - mse: 2.5826e-04 - val_loss: 8.7346e-04 - val_mse: 8.7346e-04\n",
            "Epoch 34/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5509e-04 - mse: 2.5509e-04 - val_loss: 8.6523e-04 - val_mse: 8.6523e-04\n",
            "Epoch 35/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5215e-04 - mse: 2.5215e-04 - val_loss: 8.5786e-04 - val_mse: 8.5786e-04\n",
            "Epoch 36/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4946e-04 - mse: 2.4946e-04 - val_loss: 8.5037e-04 - val_mse: 8.5037e-04\n",
            "Epoch 37/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4691e-04 - mse: 2.4691e-04 - val_loss: 8.4405e-04 - val_mse: 8.4405e-04\n",
            "Epoch 38/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4465e-04 - mse: 2.4465e-04 - val_loss: 8.3725e-04 - val_mse: 8.3725e-04\n",
            "Epoch 39/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4239e-04 - mse: 2.4239e-04 - val_loss: 8.3120e-04 - val_mse: 8.3120e-04\n",
            "Epoch 40/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4037e-04 - mse: 2.4037e-04 - val_loss: 8.2501e-04 - val_mse: 8.2501e-04\n",
            "Epoch 41/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3845e-04 - mse: 2.3845e-04 - val_loss: 8.1944e-04 - val_mse: 8.1944e-04\n",
            "Epoch 42/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3668e-04 - mse: 2.3668e-04 - val_loss: 8.1413e-04 - val_mse: 8.1413e-04\n",
            "Epoch 43/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3498e-04 - mse: 2.3498e-04 - val_loss: 8.0911e-04 - val_mse: 8.0911e-04\n",
            "Epoch 44/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3348e-04 - mse: 2.3348e-04 - val_loss: 8.0430e-04 - val_mse: 8.0430e-04\n",
            "Epoch 45/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3212e-04 - mse: 2.3212e-04 - val_loss: 7.9957e-04 - val_mse: 7.9957e-04\n",
            "Epoch 46/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3080e-04 - mse: 2.3080e-04 - val_loss: 7.9522e-04 - val_mse: 7.9522e-04\n",
            "Epoch 47/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 2.2956e-04 - mse: 2.2956e-04 - val_loss: 7.9105e-04 - val_mse: 7.9105e-04\n",
            "Epoch 48/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2843e-04 - mse: 2.2843e-04 - val_loss: 7.8722e-04 - val_mse: 7.8722e-04\n",
            "Epoch 49/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2738e-04 - mse: 2.2738e-04 - val_loss: 7.8298e-04 - val_mse: 7.8298e-04\n",
            "Epoch 50/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2632e-04 - mse: 2.2632e-04 - val_loss: 7.7929e-04 - val_mse: 7.7929e-04\n",
            "Epoch 51/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2536e-04 - mse: 2.2536e-04 - val_loss: 7.7547e-04 - val_mse: 7.7547e-04\n",
            "Epoch 52/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2450e-04 - mse: 2.2450e-04 - val_loss: 7.7201e-04 - val_mse: 7.7201e-04\n",
            "Epoch 53/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2369e-04 - mse: 2.2369e-04 - val_loss: 7.6885e-04 - val_mse: 7.6885e-04\n",
            "Epoch 54/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2296e-04 - mse: 2.2296e-04 - val_loss: 7.6553e-04 - val_mse: 7.6553e-04\n",
            "Epoch 55/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2226e-04 - mse: 2.2226e-04 - val_loss: 7.6287e-04 - val_mse: 7.6287e-04\n",
            "Epoch 56/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2161e-04 - mse: 2.2161e-04 - val_loss: 7.5990e-04 - val_mse: 7.5990e-04\n",
            "Epoch 57/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2101e-04 - mse: 2.2101e-04 - val_loss: 7.5721e-04 - val_mse: 7.5721e-04\n",
            "Epoch 58/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2044e-04 - mse: 2.2044e-04 - val_loss: 7.5447e-04 - val_mse: 7.5447e-04\n",
            "Epoch 59/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1993e-04 - mse: 2.1993e-04 - val_loss: 7.5198e-04 - val_mse: 7.5198e-04\n",
            "Epoch 60/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1947e-04 - mse: 2.1947e-04 - val_loss: 7.4974e-04 - val_mse: 7.4974e-04\n",
            "Epoch 61/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1904e-04 - mse: 2.1904e-04 - val_loss: 7.4748e-04 - val_mse: 7.4748e-04\n",
            "Epoch 62/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1862e-04 - mse: 2.1862e-04 - val_loss: 7.4533e-04 - val_mse: 7.4533e-04\n",
            "Epoch 63/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1824e-04 - mse: 2.1824e-04 - val_loss: 7.4339e-04 - val_mse: 7.4339e-04\n",
            "Epoch 64/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1792e-04 - mse: 2.1792e-04 - val_loss: 7.4104e-04 - val_mse: 7.4104e-04\n",
            "Epoch 65/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1755e-04 - mse: 2.1755e-04 - val_loss: 7.3932e-04 - val_mse: 7.3932e-04\n",
            "Epoch 66/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1725e-04 - mse: 2.1725e-04 - val_loss: 7.3765e-04 - val_mse: 7.3765e-04\n",
            "Epoch 67/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1697e-04 - mse: 2.1697e-04 - val_loss: 7.3580e-04 - val_mse: 7.3580e-04\n",
            "Epoch 68/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.1670e-04 - mse: 2.1670e-04 - val_loss: 7.3417e-04 - val_mse: 7.3417e-04\n",
            "Epoch 69/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1645e-04 - mse: 2.1645e-04 - val_loss: 7.3278e-04 - val_mse: 7.3278e-04\n",
            "Epoch 70/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1622e-04 - mse: 2.1622e-04 - val_loss: 7.3087e-04 - val_mse: 7.3087e-04\n",
            "Epoch 71/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1597e-04 - mse: 2.1597e-04 - val_loss: 7.2949e-04 - val_mse: 7.2949e-04\n",
            "Epoch 72/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1576e-04 - mse: 2.1576e-04 - val_loss: 7.2791e-04 - val_mse: 7.2791e-04\n",
            "Epoch 73/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.1557e-04 - mse: 2.1557e-04 - val_loss: 7.2655e-04 - val_mse: 7.2655e-04\n",
            "Epoch 74/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1539e-04 - mse: 2.1539e-04 - val_loss: 7.2505e-04 - val_mse: 7.2505e-04\n",
            "Epoch 75/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1521e-04 - mse: 2.1521e-04 - val_loss: 7.2364e-04 - val_mse: 7.2364e-04\n",
            "Epoch 76/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1505e-04 - mse: 2.1505e-04 - val_loss: 7.2256e-04 - val_mse: 7.2256e-04\n",
            "Epoch 77/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1491e-04 - mse: 2.1491e-04 - val_loss: 7.2121e-04 - val_mse: 7.2121e-04\n",
            "Epoch 78/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1477e-04 - mse: 2.1477e-04 - val_loss: 7.2031e-04 - val_mse: 7.2031e-04\n",
            "Epoch 79/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1465e-04 - mse: 2.1465e-04 - val_loss: 7.1893e-04 - val_mse: 7.1893e-04\n",
            "Epoch 80/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1453e-04 - mse: 2.1453e-04 - val_loss: 7.1781e-04 - val_mse: 7.1781e-04\n",
            "Epoch 81/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 2.1441e-04 - mse: 2.1441e-04 - val_loss: 7.1697e-04 - val_mse: 7.1697e-04\n",
            "Epoch 82/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.1431e-04 - mse: 2.1431e-04 - val_loss: 7.1594e-04 - val_mse: 7.1594e-04\n",
            "Epoch 83/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1422e-04 - mse: 2.1422e-04 - val_loss: 7.1485e-04 - val_mse: 7.1485e-04\n",
            "Epoch 84/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1413e-04 - mse: 2.1413e-04 - val_loss: 7.1408e-04 - val_mse: 7.1408e-04\n",
            "Epoch 85/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1406e-04 - mse: 2.1406e-04 - val_loss: 7.1328e-04 - val_mse: 7.1328e-04\n",
            "Epoch 86/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1399e-04 - mse: 2.1399e-04 - val_loss: 7.1221e-04 - val_mse: 7.1221e-04\n",
            "Epoch 87/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1391e-04 - mse: 2.1391e-04 - val_loss: 7.1145e-04 - val_mse: 7.1145e-04\n",
            "Epoch 88/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1385e-04 - mse: 2.1385e-04 - val_loss: 7.1085e-04 - val_mse: 7.1085e-04\n",
            "Epoch 89/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1380e-04 - mse: 2.1380e-04 - val_loss: 7.1021e-04 - val_mse: 7.1021e-04\n",
            "Epoch 90/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1375e-04 - mse: 2.1375e-04 - val_loss: 7.0949e-04 - val_mse: 7.0949e-04\n",
            "Epoch 91/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1370e-04 - mse: 2.1370e-04 - val_loss: 7.0889e-04 - val_mse: 7.0889e-04\n",
            "Epoch 92/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1365e-04 - mse: 2.1365e-04 - val_loss: 7.0833e-04 - val_mse: 7.0833e-04\n",
            "Epoch 93/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1361e-04 - mse: 2.1361e-04 - val_loss: 7.0774e-04 - val_mse: 7.0774e-04\n",
            "Epoch 94/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1357e-04 - mse: 2.1357e-04 - val_loss: 7.0705e-04 - val_mse: 7.0705e-04\n",
            "Epoch 95/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1352e-04 - mse: 2.1352e-04 - val_loss: 7.0643e-04 - val_mse: 7.0643e-04\n",
            "Epoch 96/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1348e-04 - mse: 2.1348e-04 - val_loss: 7.0580e-04 - val_mse: 7.0580e-04\n",
            "Epoch 97/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1345e-04 - mse: 2.1345e-04 - val_loss: 7.0549e-04 - val_mse: 7.0549e-04\n",
            "Epoch 98/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1342e-04 - mse: 2.1342e-04 - val_loss: 7.0473e-04 - val_mse: 7.0473e-04\n",
            "Epoch 99/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1339e-04 - mse: 2.1339e-04 - val_loss: 7.0424e-04 - val_mse: 7.0424e-04\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1336e-04 - mse: 2.1336e-04 - val_loss: 7.0382e-04 - val_mse: 7.0382e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89a5a446d0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCswb8QKFmZy",
        "outputId": "38dc0b47-746e-4101-8134-2a96b5e65e35"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction), validation_volatility)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.026529689148563504"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MvBZqVFUyBo",
        "outputId": "83540ed5-5aa3-46b5-c7e4-05dadf37162f"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, input_shape=[window_size], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "model.fit(train_dataset, epochs=100, validation_data=validation_dataset)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 5.1172e-04 - mse: 5.1172e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 5.0430e-04 - mse: 5.0430e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.9638e-04 - mse: 4.9638e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.8862e-04 - mse: 4.8862e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.8103e-04 - mse: 4.8103e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.7365e-04 - mse: 4.7365e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.6640e-04 - mse: 4.6640e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.5935e-04 - mse: 4.5935e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.5245e-04 - mse: 4.5245e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.4564e-04 - mse: 4.4564e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.3900e-04 - mse: 4.3900e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.3250e-04 - mse: 4.3250e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.2616e-04 - mse: 4.2616e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.1993e-04 - mse: 4.1993e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.1384e-04 - mse: 4.1384e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.0795e-04 - mse: 4.0795e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 4.0210e-04 - mse: 4.0210e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.9645e-04 - mse: 3.9645e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.9094e-04 - mse: 3.9094e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.8549e-04 - mse: 3.8549e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.8019e-04 - mse: 3.8019e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.7499e-04 - mse: 3.7499e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.6992e-04 - mse: 3.6992e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.6495e-04 - mse: 3.6495e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.6009e-04 - mse: 3.6009e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 3.5534e-04 - mse: 3.5534e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.5069e-04 - mse: 3.5069e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 28/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.4618e-04 - mse: 3.4618e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 29/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 3.4169e-04 - mse: 3.4169e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 30/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.3737e-04 - mse: 3.3737e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 31/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.3312e-04 - mse: 3.3312e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 32/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.2895e-04 - mse: 3.2895e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 33/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.2488e-04 - mse: 3.2488e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 34/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.2090e-04 - mse: 3.2090e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 35/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.1701e-04 - mse: 3.1701e-04 - val_loss: 9.9675e-04 - val_mse: 9.9675e-04\n",
            "Epoch 36/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.1325e-04 - mse: 3.1325e-04 - val_loss: 9.9030e-04 - val_mse: 9.9030e-04\n",
            "Epoch 37/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 3.0956e-04 - mse: 3.0956e-04 - val_loss: 9.8398e-04 - val_mse: 9.8398e-04\n",
            "Epoch 38/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.0592e-04 - mse: 3.0592e-04 - val_loss: 9.7773e-04 - val_mse: 9.7773e-04\n",
            "Epoch 39/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.0237e-04 - mse: 3.0237e-04 - val_loss: 9.7167e-04 - val_mse: 9.7167e-04\n",
            "Epoch 40/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.9889e-04 - mse: 2.9889e-04 - val_loss: 9.6567e-04 - val_mse: 9.6567e-04\n",
            "Epoch 41/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.9547e-04 - mse: 2.9547e-04 - val_loss: 9.5973e-04 - val_mse: 9.5973e-04\n",
            "Epoch 42/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.9214e-04 - mse: 2.9214e-04 - val_loss: 9.5389e-04 - val_mse: 9.5389e-04\n",
            "Epoch 43/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8888e-04 - mse: 2.8888e-04 - val_loss: 9.4823e-04 - val_mse: 9.4823e-04\n",
            "Epoch 44/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8571e-04 - mse: 2.8571e-04 - val_loss: 9.4262e-04 - val_mse: 9.4262e-04\n",
            "Epoch 45/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8258e-04 - mse: 2.8258e-04 - val_loss: 9.3709e-04 - val_mse: 9.3709e-04\n",
            "Epoch 46/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7956e-04 - mse: 2.7956e-04 - val_loss: 9.3172e-04 - val_mse: 9.3172e-04\n",
            "Epoch 47/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7659e-04 - mse: 2.7659e-04 - val_loss: 9.2651e-04 - val_mse: 9.2651e-04\n",
            "Epoch 48/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7370e-04 - mse: 2.7370e-04 - val_loss: 9.2128e-04 - val_mse: 9.2128e-04\n",
            "Epoch 49/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7086e-04 - mse: 2.7086e-04 - val_loss: 9.1616e-04 - val_mse: 9.1616e-04\n",
            "Epoch 50/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6807e-04 - mse: 2.6807e-04 - val_loss: 9.1113e-04 - val_mse: 9.1113e-04\n",
            "Epoch 51/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6536e-04 - mse: 2.6536e-04 - val_loss: 9.0619e-04 - val_mse: 9.0619e-04\n",
            "Epoch 52/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6267e-04 - mse: 2.6267e-04 - val_loss: 9.0120e-04 - val_mse: 9.0120e-04\n",
            "Epoch 53/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.6005e-04 - mse: 2.6005e-04 - val_loss: 8.9643e-04 - val_mse: 8.9643e-04\n",
            "Epoch 54/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5752e-04 - mse: 2.5752e-04 - val_loss: 8.9163e-04 - val_mse: 8.9163e-04\n",
            "Epoch 55/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5503e-04 - mse: 2.5503e-04 - val_loss: 8.8707e-04 - val_mse: 8.8707e-04\n",
            "Epoch 56/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5261e-04 - mse: 2.5261e-04 - val_loss: 8.8264e-04 - val_mse: 8.8264e-04\n",
            "Epoch 57/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5026e-04 - mse: 2.5026e-04 - val_loss: 8.7813e-04 - val_mse: 8.7813e-04\n",
            "Epoch 58/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4793e-04 - mse: 2.4793e-04 - val_loss: 8.7375e-04 - val_mse: 8.7375e-04\n",
            "Epoch 59/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4567e-04 - mse: 2.4567e-04 - val_loss: 8.6941e-04 - val_mse: 8.6941e-04\n",
            "Epoch 60/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4343e-04 - mse: 2.4343e-04 - val_loss: 8.6527e-04 - val_mse: 8.6527e-04\n",
            "Epoch 61/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.4128e-04 - mse: 2.4128e-04 - val_loss: 8.6117e-04 - val_mse: 8.6117e-04\n",
            "Epoch 62/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3916e-04 - mse: 2.3916e-04 - val_loss: 8.5694e-04 - val_mse: 8.5694e-04\n",
            "Epoch 63/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3706e-04 - mse: 2.3706e-04 - val_loss: 8.5291e-04 - val_mse: 8.5291e-04\n",
            "Epoch 64/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3502e-04 - mse: 2.3502e-04 - val_loss: 8.4899e-04 - val_mse: 8.4899e-04\n",
            "Epoch 65/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3304e-04 - mse: 2.3304e-04 - val_loss: 8.4508e-04 - val_mse: 8.4508e-04\n",
            "Epoch 66/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.3108e-04 - mse: 2.3108e-04 - val_loss: 8.4127e-04 - val_mse: 8.4127e-04\n",
            "Epoch 67/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2917e-04 - mse: 2.2917e-04 - val_loss: 8.3748e-04 - val_mse: 8.3748e-04\n",
            "Epoch 68/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2728e-04 - mse: 2.2728e-04 - val_loss: 8.3364e-04 - val_mse: 8.3364e-04\n",
            "Epoch 69/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2545e-04 - mse: 2.2545e-04 - val_loss: 8.2993e-04 - val_mse: 8.2993e-04\n",
            "Epoch 70/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2367e-04 - mse: 2.2367e-04 - val_loss: 8.2642e-04 - val_mse: 8.2642e-04\n",
            "Epoch 71/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2196e-04 - mse: 2.2196e-04 - val_loss: 8.2291e-04 - val_mse: 8.2291e-04\n",
            "Epoch 72/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.2026e-04 - mse: 2.2026e-04 - val_loss: 8.1952e-04 - val_mse: 8.1952e-04\n",
            "Epoch 73/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1860e-04 - mse: 2.1860e-04 - val_loss: 8.1596e-04 - val_mse: 8.1596e-04\n",
            "Epoch 74/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1696e-04 - mse: 2.1696e-04 - val_loss: 8.1263e-04 - val_mse: 8.1263e-04\n",
            "Epoch 75/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1537e-04 - mse: 2.1537e-04 - val_loss: 8.0941e-04 - val_mse: 8.0941e-04\n",
            "Epoch 76/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1383e-04 - mse: 2.1383e-04 - val_loss: 8.0629e-04 - val_mse: 8.0629e-04\n",
            "Epoch 77/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1236e-04 - mse: 2.1236e-04 - val_loss: 8.0309e-04 - val_mse: 8.0309e-04\n",
            "Epoch 78/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1088e-04 - mse: 2.1088e-04 - val_loss: 7.9998e-04 - val_mse: 7.9998e-04\n",
            "Epoch 79/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0944e-04 - mse: 2.0944e-04 - val_loss: 7.9685e-04 - val_mse: 7.9685e-04\n",
            "Epoch 80/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0802e-04 - mse: 2.0802e-04 - val_loss: 7.9395e-04 - val_mse: 7.9395e-04\n",
            "Epoch 81/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0665e-04 - mse: 2.0665e-04 - val_loss: 7.9099e-04 - val_mse: 7.9099e-04\n",
            "Epoch 82/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0530e-04 - mse: 2.0530e-04 - val_loss: 7.8797e-04 - val_mse: 7.8797e-04\n",
            "Epoch 83/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0396e-04 - mse: 2.0396e-04 - val_loss: 7.8517e-04 - val_mse: 7.8517e-04\n",
            "Epoch 84/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0270e-04 - mse: 2.0270e-04 - val_loss: 7.8228e-04 - val_mse: 7.8228e-04\n",
            "Epoch 85/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0142e-04 - mse: 2.0142e-04 - val_loss: 7.7959e-04 - val_mse: 7.7959e-04\n",
            "Epoch 86/100\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.0021e-04 - mse: 2.0021e-04 - val_loss: 7.7682e-04 - val_mse: 7.7682e-04\n",
            "Epoch 87/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9899e-04 - mse: 1.9899e-04 - val_loss: 7.7414e-04 - val_mse: 7.7414e-04\n",
            "Epoch 88/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9781e-04 - mse: 1.9781e-04 - val_loss: 7.7152e-04 - val_mse: 7.7152e-04\n",
            "Epoch 89/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9667e-04 - mse: 1.9667e-04 - val_loss: 7.6897e-04 - val_mse: 7.6897e-04\n",
            "Epoch 90/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9555e-04 - mse: 1.9555e-04 - val_loss: 7.6640e-04 - val_mse: 7.6640e-04\n",
            "Epoch 91/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9444e-04 - mse: 1.9444e-04 - val_loss: 7.6386e-04 - val_mse: 7.6386e-04\n",
            "Epoch 92/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9338e-04 - mse: 1.9338e-04 - val_loss: 7.6135e-04 - val_mse: 7.6135e-04\n",
            "Epoch 93/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9232e-04 - mse: 1.9232e-04 - val_loss: 7.5892e-04 - val_mse: 7.5892e-04\n",
            "Epoch 94/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9129e-04 - mse: 1.9129e-04 - val_loss: 7.5656e-04 - val_mse: 7.5656e-04\n",
            "Epoch 95/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9029e-04 - mse: 1.9029e-04 - val_loss: 7.5419e-04 - val_mse: 7.5419e-04\n",
            "Epoch 96/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.8931e-04 - mse: 1.8931e-04 - val_loss: 7.5187e-04 - val_mse: 7.5187e-04\n",
            "Epoch 97/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.8835e-04 - mse: 1.8835e-04 - val_loss: 7.4962e-04 - val_mse: 7.4962e-04\n",
            "Epoch 98/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.8743e-04 - mse: 1.8743e-04 - val_loss: 7.4735e-04 - val_mse: 7.4735e-04\n",
            "Epoch 99/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.8650e-04 - mse: 1.8650e-04 - val_loss: 7.4513e-04 - val_mse: 7.4513e-04\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.8561e-04 - mse: 1.8561e-04 - val_loss: 7.4300e-04 - val_mse: 7.4300e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89a593c210>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsb4RyBH3JbK",
        "outputId": "592ff59b-c7a7-4bea-9bb8-54b610334617"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction), validation_volatility)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027258098296350227"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTYnHKzu33np"
      },
      "source": [
        "## Linear Regression (Normalize)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOPX47wf3Qct"
      },
      "source": [
        "window_size = forward_window\n",
        "batch_size = 32\n",
        "shuffle_buffer=1000\n",
        "\n",
        "train_x = rolling(weekly_data_returns.WILL5000IND_Ret[training_dates].values, window_size)\n",
        "scaler_x = train_x.std()\n",
        "train_x = train_x / scaler_x\n",
        "train_y = training_volatility.WILL5000IND_Ret_Realized_Vol.values[window_size-1:][:,None]\n",
        "scaler_y = train_y.std()\n",
        "train_y = train_y / scaler_y\n",
        "train_data = np.hstack((train_x,train_y))\n",
        "\n",
        "validation_x = rolling(weekly_data_returns[weekly_data_returns.index <= validation_dates[-1]].WILL5000IND_Ret.values, window_size)[-len(validation_dates):]\n",
        "validation_y = validation_volatility.WILL5000IND_Ret_Realized_Vol.values[:,None]\n",
        "validation_x = validation_x / scaler_x\n",
        "validation_y = validation_y / scaler_y\n",
        "validation_data = np.hstack((validation_x,validation_y))\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "train_dataset = train_dataset.shuffle(shuffle_buffer)\n",
        "train_dataset = train_dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_data)\n",
        "validation_dataset = validation_dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "validation_dataset = validation_dataset.batch(batch_size).prefetch(1)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj7aZCl24Ojz",
        "outputId": "131b5d49-f31f-4fe8-d612-3a33c32d7957"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(1,input_shape=[window_size])\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=validation_dataset, verbose=0)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-v9D8EB4Qac",
        "outputId": "edd668e9-241e-4d6a-81ea-801308b9a52a"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction).mul(scaler_y), validation_volatility)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03193162502759505"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UUzsORLM6DiO",
        "outputId": "7f790404-4137-4591-d51f-e579d0a9b362"
      },
      "source": [
        "plt.plot(history.history['val_mse'],label='Validation MSE')\n",
        "plt.plot(history.history['mse'],label='Training MSE')\n",
        "plt.legend()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f89a3568c90>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8dfJZCX7vockLGFPgASQHUWLG7ggaK2Vuvvtt7Z08dv211Zrf/ZXW79qrcu3al2+lLKoFRfEBWQVEQKEPUBCEkgC2TeWhCzn98eZLCyBkEwymcnn+Xjcx8zcuTNzrlfeHD733HOV1hohhBCOx8XeDRBCCNE5EuBCCOGgJMCFEMJBSYALIYSDkgAXQggH5dqTPxYSEqLj4+N78ieFEMLhbd++vVRrHXr++h4N8Pj4eNLT03vyJ4UQwuEppfIutl5KKEII4aAkwIUQwkFJgAshhIPq0Rq4EKLn1NfXk5+fT21trb2bIjrI09OTmJgY3NzcOrS9BLgQTio/Px9fX1/i4+NRStm7OeIytNaUlZWRn59PQkJChz4jJRQhnFRtbS3BwcES3g5CKUVwcPAV/YtJAlwIJybh7Viu9Hg5RIB/e6SMNzYeoalJpr4VQohmDhHgn+w+zv9deYDvvrGF/IrT9m6OEKIDZsyYweeff37OuhdeeIFHH3203c9Mnz695WK/G264gcrKygu2efLJJ3n22Wcv+dsrVqxg//79La9/97vfsXr16itp/kWtW7cOpRRvvPFGy7qMjAyUUi1t2rJlC+PHjyclJYWhQ4fy5JNPAvD2228TGhpKSkpKy9K2jZ3hEAH+1Jzh/Pn2UezJr2LWCxtZnn4MuRGFEL3bXXfdxdKlS89Zt3TpUu66664Off7TTz8lICCgU799foA/9dRTzJw5s1Pfdb4RI0awfPnyltdLliwhOTm55fW9997La6+9RkZGBnv37mXevHkt782fP5+MjIyWZdiwYV1qi0MEuFKKeWmxfPaTqQyL8uPx93Zz/zvpFFXL8Cghequ5c+eycuVKzp49C0Bubi6FhYVMmTKFRx99lNTUVIYPH84TTzxx0c/Hx8dTWloKwNNPP83gwYOZPHkyBw8ebNnm9ddfJy0tjeTkZG6//XZOnz7N5s2b+eijj/jFL35BSkoK2dnZLFiwgPfeew+ANWvWMHr0aEaOHMl9991HXV1dy+898cQTjBkzhpEjR5KZmXnRdvXv35/a2lqKiorQWvPZZ59x/fXXt7xfXFxMZGQkABaLpcshfSkONYwwNqgfSx+cwFubc/nL55lc+9x6npw9nFtHR8vJGiEu4fcf72N/YbVNv3NYlB9P3Dy83feDgoIYN24cq1atYs6cOSxdupR58+ahlOLpp58mKCiIxsZGrrnmGnbv3s2oUaMu+j3bt29n6dKlZGRk0NDQwJgxYxg7diwAt912Gw8++CAAv/nNb/jHP/7Bj370I2bPns1NN93E3Llzz/mu2tpaFixYwJo1axg8eDDf//73efXVV/nJT34CQEhICDt27OCVV17h2WefPadU0tbcuXN59913GT16NGPGjMHDw6PlvYULF5KUlMT06dOZNWsW9957L56engAsW7aMTZs2tWz7zTff4OXldbn/1O1yiB54Wy4uivsnJ7Dqx1MZHO7LT5fv4uFF2yk9WWfvpgkhztO2jNK2fLJ8+XLGjBnD6NGj2bdv3yVrwRs3buTWW2+lX79++Pn5MXv27Jb39u7dy5QpUxg5ciSLFy9m3759l2zPwYMHSUhIYPDgwYApd2zYsKHl/dtuuw2AsWPHkpub2+73zJs3j3fffZclS5ZcUBL63e9+R3p6Otdddx3/+te/mDVrVst755dQuhLe4GA98LYSQrxZ9vBV/GPTEZ79/BDfeX4Df7xtJN8ZHmHvpgnR61yqp9yd5syZw8KFC9mxYwenT59m7Nix5OTk8Oyzz7Jt2zYCAwNZsGBBp68WXbBgAStWrCA5OZm3336bdevWdam9zT1pi8VCQ0NDu9tFRETg5ubGl19+yV//+lc2b958zvsDBgzg0Ucf5cEHHyQ0NJSysrIutas9DtcDb8vionho6gA+/tFkIvw9eXjRdh5bspMy6Y0L0Sv4+PgwY8YM7rvvvpaeanV1Nd7e3vj7+1NUVMSqVasu+R1Tp05lxYoVnDlzhpqaGj7++OOW92pqaoiMjKS+vp7Fixe3rPf19aWmpuaC70pKSiI3N5esrCwAFi1axLRp0zq1b0899RTPPPMMFovlnPUrV65sGWRx+PBhLBZLp0/GXo7D9sDbSorw5YP/mMT/rM/mb18dZuPhEp64eThzUqKkNi6End11113ceuutLaWU5ORkRo8ezZAhQ4iNjWXSpEmX/PyYMWOYP38+ycnJhIWFkZaW1vLeH/7wB8aPH09oaCjjx49vCe0777yTBx98kBdffLHl5CWYuUbeeust7rjjDhoaGkhLS+ORRx7p1H5NnDjxousXLVrEwoUL6devH66urixevLgl5M+vgb/yyivtfk9HqJ4cjpeamqq7+4YOh4pqePy93WQcq2RGUihP3zqSqICu1ZmEcEQHDhxg6NCh9m6GuEIXO25Kqe1a69Tzt3XoEsrFDA735f1HJ/KbG4ey5Ug51z2/gUVb8uQqTiGE07lsgCul3lRKFSul9l7kvZ8ppbRSKqR7mtc5FhfFA1MS+WLhVFJiA/jtir3c+foWckpP2btpQghhMx3pgb8NzDp/pVIqFrgOOGrjNtlMbFA/Ft0/jj/fPooDx6uZ9cIG/r4+m4bGJns3TQghuuyyAa613gCUX+St54HHgV5dm2i+inP1T6cxdXAo/29VJre88jW78y+cY0EIIRxJp2rgSqk5QIHWepeN29Ntwv08ee2esbz83TEUV9dxy8tf8+RH+6iprbd304QQolOuOMCVUv2AXwO/6+D2Dyml0pVS6SUlJVf6czallOLGUZGs/tk0vjehP+98k8u1z23gs70n7NouIYTojM70wAcACcAupVQuEAPsUEpd9BJIrfVrWutUrXVqaGho51tqQ36ebjw1ZwQf/MckAr3deeSf23ngnXQKK8/Yu2lCOI2ysrKWaVMjIiKIjo5ued08wVV70tPTeeyxxy77G10ZQ91Wb5smtqOu+EIerfUeIKz5tTXEU7XWpTZsV49IiQ3g4/+cxFtf5/Lcl4e49rn1/OI7SdxzVTwWF7kASIiuCA4OJiMjAzBzePv4+PDzn/+85f2GhgZcXS8eQampqaSmXjDs+QLnX8LeFc3TxD7wwAPAxaeJXb58OcnJyTQ2Np4zK+L8+fN56aWXbNaWjurIMMIlwDdAklIqXyl1f/c3q+e4Wlx4cKoZcjg2PognP97Pba9utvnMbUIIM3fJI488wvjx43n88cfZunUrV111FaNHj2bixIktobhu3TpuuukmwIT/fffdx/Tp00lMTOTFF19s+T4fH5+W7adPn87cuXMZMmQId999d8vl7J9++ilDhgxh7NixPPbYYy3fe77eNE1sR122B661vuTs61rreJu1xo5ig/rxzg/S+DCjkKc+2c/NL23i3qviWXjtIHw93ezdPCG6ZtUv4cQe235nxEi4/k9X/LH8/Hw2b96MxWKhurqajRs34urqyurVq/n1r3/N+++/f8FnMjMzWbt2LTU1NSQlJfHoo4/i5nbun8udO3eyb98+oqKimDRpEl9//TWpqak8/PDDbNiwgYSEhMveTKK3TBPbUU53JWZXKKW4ZXQ0a346jflpsby1OYdr/ns9H+0qlDsACWEjd9xxR8vcIFVVVdxxxx2MGDGChQsXtjsd7I033oiHhwchISGEhYVRVFR0wTbjxo0jJiYGFxcXUlJSyM3NJTMzk8TERBISEgAuG+C9ZZrYjnKKyaxsLdDbnT/eOpJ5qbH8dsVeHluyk3fTj/GHOSOID/G2d/OEuHKd6Cl3F2/v1j9Dv/3tb5kxYwYffPABubm5TJ8+/aKfadsTbm+q145sczm9ZZrYjpIe+CWkxAaw4oeT+P3s4ew8Wsl1L2zgr6sPU1vfaO+mCeEUqqqqiI6OBsxoDltLSkriyJEjLTdnWLZs2WU/0xumie0oCfDLsLgo7p0Yz5qfTePaYeE8v/oQM59bz2d7T0hZRYguevzxx/nVr37F6NGjO9VjvhwvLy9eeeUVZs2axdixY/H19cXf3/+Sn5k4cSK33HLLBesXLVpEUlISKSkp3HPPPRdME9t2GKEtR8dcitNNJ9vdNmeX8vuP9nOwqIbJA0N4cvYwBob52rtZQlxAppM1Tp48iY+PD1prfvjDHzJo0CAWLlxo72a1q09PJ9vdJg4IYeVjk/n97OHszq9k1gsbeXrlfrkkX4he6vXXXyclJYXhw4dTVVXFww8/bO8m2Yz0wLug7GQdf/n8IMvSjxHi48Hj30ni9jExuMhFQKIXkB64Y5IeeA8J9vHgT7ePYsV/TCIm0ItfvLebW175mu15FfZumhAAcp7GwVzp8ZIAt4Hk2ADef2Qiz89Ppqi6lttf3czCZRkUVXfuTttC2IKnpydlZWUS4g5Ca01ZWVnLxUEdISUUGztV18Ar67J4fUMOrhbFD2cM5P7JCXi6WS7/YSFsqL6+nvz8fGprpSPhKDw9PYmJibngKtP2SigS4N0kr+wUf/jkAKsPFBEd4MV/XT+Em0dFopTUx4UQV0Zq4D2sf7A3b9ybyuIHxuPn5cZjS3Zy6yubpT4uhLAZCfBuNmlgCJ/8aDJ/njuKwsoz3P7qZh5bspMCmXtcCNFFUkLpQafqGvj7+mz+vuEIAPdOjOeRaQMI8na3c8uEEL2Z1MB7kYLKM/z3Fwf5YGcB3u6uPDAlgQemJOLjIXOLCSEuJAHeCx0qquG5Lw7x2b4ThPh48JOZg7gzLRZXi1S2hBCt5CRmLzQ43Jf/uWcsK344icQQb36zYi/feWGDTJQlhOgQCfBeICU2gGUPT+C1e8YC8Mg/t3PLK5vZnO1wtxkVQvQgCfBeQinFdcMj+PwnU/nz7aMorq7lu69/y/ff3Mq+wip7N08I0QtJDbyXqq1vZNE3eby0Novq2npuSYnmp9cOJjaon72bJoToYXIS00FVnannf9Zn8+amHJq05q5xcfznjIGE+XV8vgQhhGOTAHdwJ6pq+dtXh1m27RiuFsX3r4rnoamJhPh4XP7DQgiH1ukAV0q9CdwEFGutR1jX/QW4GTgLZAM/0FpXXq4REuBdl1d2ihdWH+bDjAI8XC18b0IcD00dQKivBLkQzqorwwjfBmadt+5LYITWehRwCPhVl1soOqR/sDfPz09h9U+ncf2ICP6xKYdpf1nLs58fpOqM3BVIiL7ksgGutd4AlJ+37gutdfMdSLcAMd3QNnEJiaE+PGcN8muGhvPS2iymPPMVL6/Nktu7CdFH2GIY4X3AKht8j+iExFAf/nbXaFY+NpnU+CD+8vlBJj+zlhfXHJYeuRBOrkMnMZVS8cAnzTXwNuv/D5AK3Kbb+SKl1EPAQwBxcXFj8/LyuthkcSm78yt5cU0Wqw8U4efpyv2TE/nB5Hj8PN0u/2EhRK/UpVEoFwtwpdQC4GHgGq316Y40Qk5i9py9BVW8uOYwX+xvDfIFE+Px7ydBLoSjselcKEqpWcDjwOyOhrfoWSOi/Xnt+6l88qPJjEsI5vnVh5j0zFc881kmpSfr7N08IYQNdGQY4RJgOhACFAFPYEadeABl1s22aK0fudyPSQ/cfg4cr+bltVms3HMcD1cX7h7fn4enJRLmKxcECdHbyYU8AoDskpO8vDaLDzMKcXVRfHd8HA9PHUCEvwS5EL2VBLg4R27pKV5am8UHOwuwKMUdqTE8Mm2AzLUiRC8kAS4u6lj5aV5dn8176fk0as2c5CgenjaApAhfezdNCGElAS4u6XjVGV7fkMOSrUc5U9/INUPCeGT6ANLig+zdNCH6PAlw0SEVp87yzje5vL05l8rT9YztH8jDUxOZOTQcFxdl7+YJ0SdJgIsrcvpsA8u3HeP1jTkUVJ5hQKg3D01N5JbR0Xi4WuzdPCH6FAlw0SkNjU2s3HOc1zYcYV9hNaG+HiyYGM/d4+MI6Odu7+YJ0SdIgIsu0VrzdVYZf9+QzcbDpXi5WZiXGsP9kxOJC5aRK0J0JwlwYTMHjlfzxsYcPtpVQGOT5voRkTw4NZGU2AB7N00IpyQBLmzuRFUtb2/OZfG3edTUNpDaP5AFk+L5zvAI3Cxyv2whbEUCXHSbk3XmhOc73+SSV3aaCD9P7rmqv9TJhbARCXDR7RqbNOsOFvPW17lsyjJ18rljY1gwKZ4BoT72bp4QDksCXPSozBPV/GNjDh9mFHK2sYnJA0P43oT+zBwahquUV4S4IhLgwi5KaupYtu0o//r2KIVVtUQHeHHvxP7MT4vD30vmJheiIyTAhV01NDaxJrOYNzfl8G1OOd7uFm4fG8M9E/ozKFzmXRHiUiTARa+xt6CKNzfl8Mnu45xtbGJCYhDfm9Cf64ZF4O4q5RUhzicBLnqdspN1LE/PZ/G3eeRXnCHEx4P5aTHcmRYn09oK0YYEuOi1Gps0Gw6XsHhLHl9lFqOBGUlh3D0+julJYVhkEi3Rx0mAC4dQUHmGZVuPsnTbMYpr6ogO8OLuCXHcmRZHkLeMKRd9kwS4cCj1jU2s3l/Eoi15bM4uw93VhZtHRfHd8bGMiQtEKemVi75DAlw4rENFNbyzOZcPdhZw+mwjA8N8uDMtlltHRxPs42Hv5gnR7STAhcM7WdfAyt2FLN12jJ1HK3GzKGYODWdeWixTB4VKrVw4LQlw4VQOFdWwfNsx/r2zgPJTZ4ny9+SO1FjmpcUSHeBl7+YJYVMS4MIpnW1oYvWBIpZsPcqmrFIApg0O5a5xcVw9JExmRRROodMBrpR6E7gJKNZaj7CuCwKWAfFALjBPa11xuUZIgIvudKz8NMvTj7E8/RhF1XWE+Xpw65ho5o6Jkas9hUPrSoBPBU4C/9smwP8MlGut/6SU+iUQqLX+r8s1QgJc9ISGxibWHixh6dajrDtUQmOTZmS0P/NSY5idEi1zsAiH06USilIqHvikTYAfBKZrrY8rpSKBdVrrpMt9jwS46GmlJ+v4MKOQ97bnc+B4NR6uLlw/IoJ5qbFMSAzGRU58Cgdg6wCv1FoHWJ8roKL59UU++xDwEEBcXNzYvLy8zu6DEF2yt6CKZduOsSKjgJraBqIDvLh9TDS3jokhIcTb3s0Tol3dFuDW1xVa68DLfY/0wEVvUFvfyBf7i3hvez4bD5egNSTH+DM7JZqbkyMJ8/W0dxOFOEd7Ae7aye8rUkpFtimhFHeteUL0HE83C7OTo5idHMWJqlo+3lXIiowC/vDJfv746QGmDArhtjExXDs0HC93i72bK0S7OtsD/wtQ1uYkZpDW+vHLfY/0wEVvllVcwwc7C/hgRwGFVbV4u1uYOSycm0ZFMXVwCB6uEubCProyCmUJMB0IAYqAJ4AVwHIgDsjDDCMsv1wjJMCFI2hq0mzJKePjXYWs2nuCytP1+Hm6csPISGanRDEhQU5+ip4lF/II0Qn1jU18nVXKRxmFfL7vBKfONhLh58mNoyKZnRzFqBh/mVhLdDsJcCG66MzZRr48UMRHGYWsP1RMfaOmf3A/5iRHMWd0NANCfezdROGkJMCFsKGq0/V8tu84H+0qZHN2GVrDyGh/bhwVyQ0jIokLljsKCduRABeimxRVm5EsH+8qZFd+FQAjov24cWQUN46UMBddJwEuRA84Vn6az/ae4JM9x9l1rBKQMBddJwEuRA/LrzjNqj3nhvnIaH9uGBkpYS6uiAS4EHZ0rPw0q/YeZ+Xu4+eUWa4fEcmsERFyAlRckgS4EL1ES5jvOdHSMx8c7sN1wyK4dli4DE0UF5AAF6IXKqw8wxf7TrBq7wm25ZbTpCHCz5NrhoZx7bBwrhoQLFeACglwIXq7ilNn+SqzmC/3F7H+UAln6hvx8XBlWlIos4ZHMD0pFF9Pmcu8L5IAF8KB1NY38nVWKV/uL+LL/UWUnTqLu8WFqwYEc83QMK4eEkZMoJwE7SskwIVwUI1Nmh1HK/h87wlWHygit+w0AEMifLluWDjXDY9geJSf1M2dmAS4EE4iu+Qkaw4UsXp/MdvyytEaIv09uXpIGDOHmrq5p5vUzZ2JBLgQTqjsZB1rMotZvb+ITVmlnD7biKebC5MHhjBjiCm1RPp72buZooskwIVwcrX1jWw5UsZXmcV8lVlMfsUZAJLCfZmWFMr0pFDS4oNws7jYuaXiSkmAC9GHaK05XHySdQeLWX+ohK055dQ3anw9XZk2OJSZQ8OZOjiUIG93ezdVdIAEuBB92Km6Br7OKmXNgWLWZBZTerIOpSAlNoDpg8OYnhTKyGh/uVFFLyUBLoQAzB2HdhdUse5gMesOlrArvxKtIcjbnSmDQpg2OJQpg0IJ9fWwd1OFlQS4EOKiyk7WsSmrlPUHS9hwuITSk2cBGBbpx5TBIUweGEJafJCMbLEjCXAhxGU1NWn2H69m/aESNhwqYcfRCuobNR6uLoxLCGLKoBCmDg4lKdxXxp33IAlwIcQVO1XXwNaccjYeLmVTVgmHik4CEOLjweSBwUweFMrkgSFE+HvauaXOrb0Ad7VHY4QQjsHbw5UZQ8KYMSQMgBNVtWw4XMKmw6VsPFzKioxCABJDvLlqQDCTBoZwVWIwgTK6pUdID1wI0SlNTZrMEzVszi5lc3YZ3x4p49TZRpQy9fOJA4KZOCCEtIQgfDykr9gV3VJCUUotBB4ANLAH+IHWura97SXAhXBe9Y1N7M6vZHNWGV9nl7Ijr5KzjU1YXBQjo/0ZnxjEhMRg0uIl0K+UzQNcKRUNbAKGaa3PKKWWA59qrd9u7zMS4EL0HbX1jezIq+CbI2VsOVJGxrFK6hs1LgqGR/mTFh/E+MQgxicEEdBPSi6X0l01cFfASylVD/QDCrv4fUIIJ+HpZmHiwBAmDgwB4MzZRrbnVbA1p4ytueUs/jaPN7/OQSkYGuHHhMRgxiUEMS4hSK4Q7aCullB+DDwNnAG+0FrffZFtHgIeAoiLixubl5fX6d8TQjiPuoZGdudX8U12Gd9kl7HjaAV1DU2AucVcanwQ4+KDSEsIIjqgb0/I1R0llEDgfWA+UAm8C7yntf5ne5+REooQoj11DY3sya/i25xyvs0pZ0deBSfrGgCIDvAiLT6QtARTchkQ6tOnxqF3RwllJpCjtS6x/sC/gYlAuwEuhBDt8XC1kBofRGp8ED+cYW5kceB4Ndtyy9mWW86mrLKWYYvB3u6kxQcxtn8gY/oHMDzKv09eKdqVAD8KTFBK9cOUUK4BpHsthLAJi4tiRLQ/I6L9+cGkBLTW5JadZmtOGd/mmFD/bN8JANwsZtu0+CBS+wcytn8gwT7OP5dLV2vgv8eUUBqAncADWuu69raXEooQwpZKaurYebSC7Ucr2J5bwe78Ks42mjp6Qog3Y+JMD31MXCCDw32xOOhsi3IpvRDC6dXWN7KnoIrteRUtS/kpMzmXt7uF5NiAllAfHRvoMFeMyqX0Qgin5+lmIS0+iLT4IMDc2OJo+Wl2Hq1kx9EKdhyt4NX12TQ2mY5rfHA/UmIDGB0XSEpsAEMj/XB3dZw7FkmACyGcllKK/sHe9A/25pbR0QCcPtvA7vwqdh6tJONYBZuzW0+Ouru6MDzKj5TYAFJiA0iOCaB/cL9eO+JFSihCiD5Na83xqloyjlWa5WglewqqOFPfCEBgPzeSrWGeHOvPyOiAHr/ZhZRQhBDiIpRSRAV4ERXgxQ0jIwFoaGziYFENu45VsetYJbvyK9lw6DDWyguR/p6MivFnVIwJ9hHRfnaZDkB64EII0QGn6hrYV1jN7vxKdudXsTu/ktyy0y3vxwR6MTK6OdT9GRnjj6+nm01+W3rgQgjRBd4eri1ztTSrOl3PnoIq9hZWsaegij35Vazae6Ll/YQQb4ZH+TE8yp+bRkUSG9TPpm2SABdCiE7y7+fG5EEhTB4U0rKu4tRZdheY0su+wioyjlXyye7jJMf4S4ALIURvFujtzrTBoUwbHNqyrvL0WbzcbX+pvwS4EEJ0s+46wek4I9aFEEKcQwJcCCEclAS4EEI4KAlwIYRwUBLgQgjhoCTAhRDCQUmACyGEg5IAF0IIByUBLoQQDkoCXAghHJQEuBBCOCgJcCGEcFAS4EII4aC6FOBKqQCl1HtKqUyl1AGl1FW2apgQQohL6+p0sn8FPtNaz1VKuQO2na1cCCFEuzod4Eopf2AqsABAa30WOGubZgkhhLicrpRQEoAS4C2l1E6l1BtKKe/zN1JKPaSUSldKpZeUlHTulzI/hY3/DaWHu9BcIYRwLl0JcFdgDPCq1no0cAr45fkbaa1f01qnaq1TQ0NDz3+7Y3I2wJqn4KVUeHk8rP0jlBzqQtOFEMLxdSXA84F8rfW31tfvYQLd9q7/EyzcB9f/GbxDYf2f4eU0+PtU2Pw3qMrvlp8VQojeTGmtO/9hpTYCD2itDyqlngS8tda/aG/71NRUnZ6e3unfa1FzAva+D3vehcKdZl3sBBhxGwybA74RXf8NIYToJZRS27XWqRes72KApwBvAO7AEeAHWuuK9ra3WYC3VZYN+/4Nez+A4n2AgvjJMPxWE+beIbb9PSGE6GHdEuBXqlsCvK2Sg7D336Z3XnYYlAvET4Hht8CQm8GnkzV4IYSwo74R4M20hqK9sG8F7F8BZVkmzOMmwrDZMPRm8Ivq/nYIIYQN9K0Ab0trKNoHBz6C/R9CSaZZHzvelFiG3gwBcT3bJiGEuAJ9N8DPV3IIDnxowvzEHrMuMgWG3mTKLKFJoJR92yiEEG1IgF9MWTZkfgIHPob8bWZd8EAYchMMnQ1Ro8FF5vsSQtiXBPjlVBdC5koT6LmboKkBfKNgyI2md95/Eljc7N1KIUQfJAF+JU6Xw+EvTM88azU01IKHPwyaCUk3wMCZ4BVg71YKIfqI9gK8q7MROqd+QZB8p1nOnoIj68x8LIc+M0MUXVxNjzzpehg8C4IS7N1iIUQfJD3wK9HUCPnpcPBTs5Ra52MJHQqDv2MCPSYNXAUL+/8AAA3ASURBVCz2bacQwqlICaU7lGXDoc/h0CrI22zq5l6BMPBaGHQdDLzG9OaFEKILJMC7W20VZH8FBz+DrC/hdJm5eCg61YT5oGshYpSMahFCXDEJ8J7U1AiFGeZE6OHPWyfc8gmHAVfDgGtgwAyZp0UI0SES4PZ0shiy1pieefZaOFMOKDPOfNC1ZlRL1BiwyDllIcSFJMB7i+beedZqsxSkg24ywxQTpkDidNNLD0qUK0KFEIAMI+w9XCwQM9Ys0//LjDk/sg6OrIXsdeZCIjDzsyTOMKWWhGlyMlQIcQHpgfcmWkP5EXMy9Mg6cyu5umpAQWQyJE4zPfTYCeDez75tFUL0GCmhOKLGBijcYcI8e62Zr6WpHizuZjbFhGkm1KV+LoRTkwB3BmdPQd43ptySs751NkV3H+g/0dy8ImGKdbiiXEwkhLOQGrgzcPc287EMmmlenyqD3A2m1JKz0QxbBPD0h/6TTZj3nwThI2T8uRBOSALckXkHm3t/Dr/VvK4+bmZSbA71gyvNes8Aaw99slnCR0gPXQgnIAHuTPwiYdQdZgGoyofcryF3I+R9beZvATNkMW48xF1leuhRo8HV3X7tFkJ0igS4M/OPgeT5ZgGoKjBBnrsJjn7TWnJx9YKYVBPm/a8yE3K5e9uv3UKIDpEA70v8o2HUPLMAnCo1k3DlbTbBvv4ZQJvpciOTzXDFOOviE2bXpgshLtTlUShKKQuQDhRorW+61LYyCqWXq62CY1tNoB/dAgXbobHOvBeYYIYuxo4zj2FDpY4uRA/pzlEoPwYOAH42+C5hT57+Zm6WQdea1w1n4fguU2459i1kr4HdS8177r7WK0rHmVCPSTVT6QohekyXAlwpFQPcCDwN/NQmLRK9h6s7xKaZBcyVohU5cGwb5G81ob7xWTOXC0BIknX78WYa3dAk6aUL0Y262gN/AXgc8G1vA6XUQ8BDAHFxcV38OWFXSplJtoISW0+M1p00V4se+9YEe+ZK2PlP8567jxnhEj3W9NCjU81IGSGETXQ6wJVSNwHFWuvtSqnp7W2ntX4NeA1MDbyzvyd6KQ8fSJhqFjC99LIsUz/PTzezLX7zspkCAMAv2hrqY8wUANFjTOlGCHHFutIDnwTMVkrdAHgCfkqpf2qtv2ebpgmHpBSEDDJL8p1mXX0tnNhtDfTtpsfePOsiQMhgE+bNwR4xEty87NN+IRyITeZCsfbAfy6jUESHnS6H4xnWnro11E8WmfeUxYxyiUqByBQT7OHDJdRFnyVzoYjepV+Q9fZyV7euqy6Egh0m2At3wsFVrfV0ZYHQIW1CPcVMCSDT6oo+TGYjFL2X1lB1zAxlPL7L3MmocCecLjXvKxcz8iVylJmBMWKkWeTmF8LJSA9cOB6lzJ2JAuJg6M1mndZQXWDC/MRuE+w5G2D3stbP+ceZUI9Mtob6KPCLklvUCacjAS4ci1Jmjhf/GBja5pTLyRIT6Cd2w3HrY+ZKwPovTK8giBhhyi7hw81j6BBw87TLbghhCxLgwjn4hMLAa8zSrK4Giva3BnvRPkh/CxrOmPeVxYyAiWgT6mHDpLcuHIYEuHBeHr7WaXPHt65raoTyHCjaAyf2mrsaHd0Ce95t3cbT3wR52FDzGD7cPHoF9Pw+CHEJEuCib3GxQMhAszTfCAPgTCUU7ze99OID5vme96HuzdZtfKMgbAiEDj330aPdC5GF6FYS4EKA6V33n2iWZs0nTIv2Q8mB1mBPf7O1DAPgF2MN9CGm1x46xJRmPGV+N9G9JMCFaE/bE6aDr2td39QIlXnWQD8AJQdNwOdugoba1u18oyB0sBnqGJpkgj10iLkVnhA2IAEuxJVysbRO6jXkxtb1TY1Qkdsa6CWHoPQgZCyGsydbt/MKMj305ikHQgabJaA/WOSPpOg4+b9FCFtxsUDwALMMuaF1fXMppiQTijOh7DCUHrZeabqozefdICjBhHnwwHMX7xAZGSMuIAEuRHdrW4oZOPPc985UQGkWlB5qDfbSw3Do89YZHMHciDp4QJtQt/5FETRAau19mAS4EPbkFXjuTTOaNTZA1VET7uXZZoresqw2Qx7bTIHhHWqCvCXUreWdwAQJdycnAS5Eb2RxbQ3i89WfgfIjUJZtDfdsM7Y9a42pt7fVL8R8R/AAE+hBiaZME5Ro/vKQsoxDkwAXwtG4eVmvHB1+4Xt1NeZEavkRE+rl1nDP2Qi7lpy7rYc/BMVbgz0BAq3PA/uboZFyQrXXkyMkhDPx8G2dlfF89WegIs8a7kdM0FfkmKtRM1eeW3NXFlOzD4w3gR4Yb0bJBPQ3r71DpffeC0iAC9FXuHmZC47Chlz4XlOjGSlTnmPGuFfkWpc8M1rmVMl539WvdabItot/HATESsD3EAlwIYQZAtkcwhdTdxIqj1rDPa/1eWWeuaF1bdW527t6WkfexJpA948zrwNizaNfNFjcun+/nJwEuBDi8jx8IHyYWS6mtsoa6sfMTTgqj0JVvnl+8DM4VXzeBxT4RrSGectjtKm/+0eDdxi4uHT7rjkyCXAhRNd5+rdfewdTf68ubBPs+a0BX7TXjHtvO78MmAub/CJbA90vyoS8X5vn3qF9OuQlwIUQ3c/Nq3Wc+sVobW50XZ0PVQWmHl+Vb30sgGNbzV8AbU+0Ari4mjln/KJM2PtGmZ69XxT4RlrXRTrtDbElwIUQ9qeUmeTLO9jcCu9imprM/VCrC61LAdQcbw38E3vg0BdQf+rCz3oGWEM9wgT6+Y8+4WZxde/e/bQxCXAhhGNwcQGfMLNEpVx8G62hrhqqj0NNofXRulQfh5MnzGRjNSdAN174ea8ga7CHnxvsPmEm7Jtfe/h07752kAS4EMJ5KGXq8Z7+Fx8u2aypEU6XnRvsNUXnPpYchJNF0NRw4efdfax/mYS3ebQ+9w4zt/jzCTc1elePbtvdTge4UioW+F8gHDMxw2ta67/aqmFCCNFtXCytvfn2SjZgyjZnKkyQt4R726XY3PDjyLoLh1I28/Q3oX7zCxA/2aa70ZUeeAPwM631DqWUL7BdKfWl1nq/jdomhBD25eLSWptvbwhls/paM1zyZIn1sajN82JTh7exTge41vo4cNz6vEYpdQCIBiTAhRB9j5vnpS+G6gY2GUCplIoHRgPfXuS9h5RS6Uqp9JKSkvPfFkII0UldDnCllA/wPvATrXX1+e9rrV/TWqdqrVNDQ0O7+nNCCCGsuhTgSik3THgv1lr/2zZNEkII0RGdDnCllAL+ARzQWj9nuyYJIYToiK70wCcB9wBXK6UyrMsNl/uQEEII2+jKKJRNgEz4K4QQdtJ3p/ESQggHJwEuhBAOSmmte+7HlCoB8jr58RCg1IbNcRR9cb/74j5D39zvvrjPcOX73V9rfcE47B4N8K5QSqVrrVPt3Y6e1hf3uy/uM/TN/e6L+wy2228poQghhIOSABdCCAflSAH+mr0bYCd9cb/74j5D39zvvrjPYKP9dpgauBBCiHM5Ug9cCCFEGxLgQgjhoBwiwJVSs5RSB5VSWUqpX9q7Pd1BKRWrlFqrlNqvlNqnlPqxdX2QUupLpdRh62Ogvdtqa0opi1Jqp1LqE+vrBKXUt9bjvUwp5Vi3Cu8ApVSAUuo9pVSmUuqAUuoqZz/WSqmF1v+39yqlliilPJ3xWCul3lRKFSul9rZZd9Fjq4wXrfu/Wyk15kp+q9cHuFLKArwMXA8MA+5SSl3m3kYOqfkWdcOACcAPrfv5S2CN1noQsMb62tn8GDjQ5vUzwPNa64FABXC/XVrVvf4KfKa1HgIkY/bfaY+1UioaeAxI1VqPACzAnTjnsX4bmHXeuvaO7fXAIOvyEPDqlfxQrw9wYByQpbU+orU+CywF5ti5TTantT6utd5hfV6D+QMdjdnXd6ybvQPcYp8Wdg+lVAxwI/CG9bUCrgbes27ijPvsD0zFTMeM1vqs1roSJz/WmMnzvJRSrkA/zC0Zne5Ya603AOXnrW7v2M4B/lcbW4AApVRkR3/LEQI8GjjW5nW+dZ3TOu8WdeHW+48CnADC7dSs7vIC8DjQZH0dDFRqrRusr53xeCcAJcBb1tLRG0opb5z4WGutC4BngaOY4K4CtuP8x7pZe8e2S/nmCAHep1zqFnXajPl0mnGfSqmbgGKt9XZ7t6WHuQJjgFe11qOBU5xXLnHCYx2I6W0mAFGANxeWGfoEWx5bRwjwAiC2zesY6zqn084t6oqa/0llfSy2V/u6wSRgtlIqF1MauxpTGw6w/jMbnPN45wP5Wuvmm4C/hwl0Zz7WM4EcrXWJ1roe+Dfm+Dv7sW7W3rHtUr45QoBvAwZZz1a7Y058fGTnNtncJW5R9xFwr/X5vcCHPd227qK1/pXWOkZrHY85rl9pre8G1gJzrZs51T4DaK1PAMeUUknWVdcA+3HiY40pnUxQSvWz/r/evM9OfazbaO/YfgR83zoaZQJQ1abUcnla616/ADcAh4Bs4P/Yuz3dtI+TMf+s2g1kWJcbMDXhNcBhYDUQZO+2dtP+Twc+sT5PBLYCWcC7gIe929cN+5sCpFuP9wog0NmPNfB7IBPYCywCPJzxWANLMHX+esy/tu5v79hi7mr2sjXb9mBG6XT4t+RSeiGEcFCOUEIRQghxERLgQgjhoCTAhRDCQUmACyGEg5IAF0IIByUBLoQQDkoCXAghHNT/BzUsSJ1sF944AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz-e5CXi6aaP"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256,input_shape=[window_size]),\n",
        "  tf.keras.layers.Dense(128),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=validation_dataset, verbose=0)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9jO0aWu290Uw",
        "outputId": "7c91f65c-820e-4932-fff4-4ef4a45f7ed8"
      },
      "source": [
        "plt.plot(history.history['val_mse'],label='Validation MSE')\n",
        "plt.plot(history.history['mse'],label='Training MSE')\n",
        "plt.legend()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f899da4b410>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8deZJTNJJiF7WAIkbIEIZCHsoFA3QNwQRFwRRaXWhbq0+rXVtvprbalVarUKVhQpm1vdEJVCQUEwYNh3CBCQEAJZyL6c3x93CAESSCDJnZl8no/HfdyZu83nevE9N2fuPVdprRFCCOG5LGYXIIQQ4twkqIUQwsNJUAshhIeToBZCCA8nQS2EEB7O1hQbjYiI0LGxsU2xaSGE8Elr1649qrWOrG1ekwR1bGwsaWlpTbFpIYTwSUqpfXXNk6YPIYTwcBLUQgjh4SSohRDCwzVJG7UQovmUl5eTmZlJSUmJ2aWIenA6ncTExGC32+u9jgS1EF4uMzOToKAgYmNjUUqZXY44B601OTk5ZGZmEhcXV+/1pOlDCC9XUlJCeHi4hLQXUEoRHh7e4L9+JKiF8AES0t7jQo6VxwR1SXklM5bv4fs9OWaXIoQQHsVjglopmPntHv7+351mlyKEqKfhw4ezePHi06a9/PLLTJkypc51hg0bVn1D3KhRo8jNzT1rmeeee45p06ad87M//vhjtmzZUv3+t7/9Ld98801Dyq/VsmXLUEoxc+bM6mnp6ekopapr+v777+nfvz9JSUn06NGD5557DoBZs2YRGRlJUlJS9VCzxgvlMUHtsFmZNDiO73blsDEzz+xyhBD1MGHCBObNm3fatHnz5jFhwoR6rf/FF18QEhJyQZ99ZlD//ve/54orrrigbZ2pZ8+eLFiwoPr93LlzSUxMrH5/11138eabb5Kens6mTZu4+eabq+eNHz+e9PT06iEhIeGi6/GYoAaY0L8DQQ4bbyzfbXYpQoh6GDt2LJ9//jllZWUAZGRkcOjQIYYOHcqUKVNITU3lkksu4dlnn611/djYWI4ePQrACy+8QLdu3RgyZAjbt2+vXmbGjBn07duXxMREbrrpJoqKili5ciWffPIJTzzxBElJSezevZuJEyfy/vvvA7BkyRKSk5Pp1asXkyZNorS0tPrznn32WVJSUujVqxfbtm2rta6OHTtSUlJCVlYWWmu+/PJLRo4cWT3/yJEjtGnTBgCr1dooYXwuHnV5XrDTzq0DOjBj+R725RTSMTzQ7JKE8Cq/+3QzWw7lN+o2E9oG8+y1l9Q6LywsjH79+rFo0SKuv/565s2bx80334xSihdeeIGwsDAqKyu5/PLL2bBhA7179651O2vXrmXevHmkp6dTUVFBSkoKffr0AWDMmDFMnjwZgGeeeYa33nqLhx56iOuuu47Ro0czduzY07ZVUlLCxIkTWbJkCd26dePOO+/k9ddf59FHHwUgIiKCdevW8dprrzFt2rTTmjhqGjt2LAsXLiQ5OZmUlBQcDkf1vKlTpxIfH8+wYcMYMWIEd911F06nE4D58+fz7bffVi+7atUq/P396/Ofuk4edUYNMGlwHDaLhZkr9ppdihCiHmo2f9Rs9liwYAEpKSkkJyezefPmc7bVrlixghtvvJGAgACCg4O57rrrqudt2rSJoUOH0qtXL+bMmcPmzZvPWc/27duJi4ujW7dugNFMsXz58ur5Y8aMAaBPnz5kZGTUuZ2bb76ZhQsXMnfu3LOacn7729+SlpbGVVddxb///W9GjBhRPe/Mpo+LDWnwsDNqgOhgJzcmt2NB2gEevaIr4S7H+VcSQgDUeebblK6//nqmTp3KunXrKCoqok+fPuzdu5dp06bxww8/EBoaysSJEy/4zsmJEyfy8ccfk5iYyKxZs1i2bNlF1XvyzNhqtVJRUVHncq1bt8Zut/P111/zyiuvsHLlytPmd+7cmSlTpjB58mQiIyPJyWm6K9Y87owaYPKlnSitqOKdlRlmlyKEOA+Xy8Xw4cOZNGlS9Zlnfn4+gYGBtGrViqysLBYtWnTObVx66aV8/PHHFBcXU1BQwKefflo9r6CggDZt2lBeXs6cOXOqpwcFBVFQUHDWtuLj48nIyGDXrl0AzJ49m8suu+yC9u33v/89L774Ilar9bTpn3/+OVprAHbu3InVar3gH0Xrw+POqAG6RLm4KiGaWSszuO+yzrgcHlmmEMJtwoQJ3HjjjdVNIImJiSQnJ9O9e3fat2/P4MGDz7l+SkoK48ePJzExkaioKPr27Vs97w9/+AP9+/cnMjKS/v37V4fzLbfcwuTJk5k+fXr1j4hg9KXx9ttvM27cOCoqKujbty8PPPDABe3XoEGDap0+e/Zspk6dSkBAADabjTlz5lSH+Zlt1K+99lqd26kvdfJboTGlpqbqi31wQPqBXG74x3c8NbI791/WuZEqE8L3bN26lR49ephdhmiA2o6ZUmqt1jq1tuU9sukDIKl9CEO6RDBjxV5KyivNLkcIIUzjsUEN8ODwLhw9UcrCtANmlyKEEKbx6KAe0CmMlA4h/PN/eyivrDK7HCGEMIVHB7VSigeHd+FgbjGfpB8yuxwhhDCFRwc1wM+6R9GjTTCvLt1FhZxVCyFaII8PaqUUU6/oyt6jhXywLtPscoQQotl5fFADXJkQTWL7EKYv2UVphVwBIoSnyMnJqe7Os3Xr1rRr1676/cmOmuqSlpbGww8/fN7PuNhrkE/yxO5L68sr7iRRSvH4Vd244601zF29n4mD6/+sMSFE0wkPDyc9PR0w+pB2uVw8/vjj1fMrKiqw2WqPmdTUVFJTa71s+DRn3rp9MU52X3rvvfcCtXdfumDBAhITE6msrDytF7/x48fz6quvNlotDeEVZ9QAQ7pE0D8ujFeX7qa4TM6qhfBUEydO5IEHHqB///48+eSTrFmzhoEDB5KcnMygQYOqw2/ZsmWMHj0aMEJ+0qRJDBs2jE6dOjF9+vTq7blcrurlhw0bxtixY+nevTu33XZb9W3cX3zxBd27d6dPnz48/PDD1ds9k6d1X1pfXnFGDe6z6qvjGffPVbyzKoMH5G5FIc626NdweGPjbrN1Lxj5pwatkpmZycqVK7FareTn57NixQpsNhvffPMNTz/9NB988MFZ62zbto2lS5dSUFBAfHw8U6ZMwW63n7bMjz/+yObNm2nbti2DBw/mu+++IzU1lfvvv5/ly5cTFxd33ocWeFL3pfXlNWfUAH1jwxgWH8lrS3eRW3Tu9i8hhHnGjRtX3fdFXl4e48aNo2fPnkydOrXObkqvueYaHA4HERERREVFkZWVddYy/fr1IyYmBovFQlJSEhkZGWzbto1OnToRF2c0iZ4vqD2p+9L68poz6pN+NaI7o6av4NX/7uKZ0Z7xZ4kQHqOBZ75NJTDw1EM/fvOb3zB8+HA++ugjMjIyGDZsWK3r1DyzrasL0voscz6e1H1pfXnVGTVAjzbBjE2J4d1V+zhwrMjscoQQ55GXl0e7du0A4+qJxhYfH8+ePXuqHwIwf/78867jKd2X1pfXBTXAY1fFY7HAXxZvP//CQghTPfnkkzz11FMkJydf0Bnw+fj7+/Paa68xYsQI+vTpQ1BQEK1atTrnOoMGDeKGG244a/rs2bOJj48nKSmJO+6446zuS2tenteYV6Ocj8d2c3o+0xZv59Wlu/jkF4PpHWP+N54QZpFuTuHEiRO4XC601jz44IN07dqVqVOnml1WnXymm9Pzuf+yToQH+vH851tpii8bIYT3mDFjBklJSVxyySXk5eVx//33m11So/LaoA5y2nn0ym6s2XuMxZvP/nVYCNFyTJ06lfT0dLZs2cKcOXMICAgwu6RG5bVBDTChb3u6Rbv446Ktcmu5aNHkr0rvcSHHyquD2ma18H/XJLAvp4h3V+4zuxwhTOF0OsnJyZGw9gJaa3Jycqpvoqkvr7uO+kyXdYtkWHwk0/+7kzEp7Qh3Oc6/khA+JCYmhszMTLKzs80uRdSD0+kkJiamQet4fVADPHNND65+eQV/+2YHz9/Qy+xyhGhWdru9+q484Zu8uunjpC5RQdzevwP/Xr2fTQfzzC5HCCEalU8ENcAvr4onLNDB0x9tpLJK2uqEEL6jXkGtlJqqlNqslNqklJqrlGpYS3gzaOVv5zeje7AhM485q+WHRSGE7zhvUCul2gEPA6la656AFbilqQu7ENcltmVIlwj+8uV2juSXmF2OEEI0ivo2fdgAf6WUDQgAPPKR4Eop/nBDT0orq/j9Z833mBwhhGhK5w1qrfVBYBqwH/gJyNNaf3Xmckqp+5RSaUqpNDMvE4qLCOTBYV34bMNP/Heb3LEohPB+9Wn6CAWuB+KAtkCgUur2M5fTWr+ptU7VWqdGRkY2fqUN8MCwTnSLdvF/H22ioKTc1FqEEOJi1afp4wpgr9Y6W2tdDnwINM5jgZuIw2blTzf15nB+CX/+UrpCFUJ4t/oE9X5ggFIqQCmlgMuBrU1b1sVL6RDKxEGxzP5+Hz9kHDO7HCGEuGD1aaNeDbwPrAM2utd5s4nrahSPXxVPuxB/fvXBBkrKpdMmIYR3qtdVH1rrZ7XW3bXWPbXWd2itS5u6sMYQ6LDxp5t6sSe7kJe+3mF2OUIIcUF85s7EugztGsmt/TswY8Ue0qQJRAjhhXw+qAGeHtWDdiH+PL5wPcVl0gQihPAuLSKoXQ4bfx7bm4ycIl78cpvZ5QghRIO0iKAGGNQ5gomDYpm1MoNvdx41uxwhhKi3FhPUAL8a0Z0uUS5+uSCdY4VlZpcjhBD10qKC2t/PyvRbksktKufJ9zfIo4uEEF6hRQU1QELbYH49sjvfbM3ivdX7zS5HCCHOq8UFNcDdg2MZFh/J859tYUdWgdnlCCHEObXIoFZK8ZexiQQ5bTw890e5a1EI4dFaZFADRAY5mDYukW2HC/jTIrlkTwjhuVpsUAMMi49i0uA4Zq3MkL6rhRAeq0UHNcCTI+Lp3jqIJxZukMd3CSE8UosPaqfdyt8nJFNYVsFDc3+korLK7JKEEOI0LT6oAbpGB/HCDb1YvfeY9LInhPA4EtRuN/WJ4Za+7Xlt2W5prxZCeBQJ6hqeu+4SEtoEM3X+eg4cKzK7HCGEACSoT+O0W3n99hSqtGbyu2kUllaYXZIQQkhQn6ljeCCv3prCjqwCfrkgnaoq6Q9ECGEuCepaXNYtkqdH9WDx5ixeXrLT7HKEEC2czewCPNU9Q+LYfriA6Ut20jXKxbWJbc0uSQjRQskZdR2UUjx/Y0/6xoby2ML1rN0nz1sUQphDgvocHDYrb9yRSrsQf+59J42Mo4VmlySEaIEkqM8jLNCPtyf2BeDuWT9wXJ4MI4RoZhLU9RAbEciMO1M5mFvMve+mSbeoQohmJUFdT6mxYbw8Pol1+4/z0NwfqZTL9oQQzUSCugFG9WrDs6MT+HpLFs9+skmeuSiEaBZyeV4DTRwcx0/5Jbzxvz1EBzl56PKuZpckhPBxEtQX4FdXdyc7v5S/fr2DkAA7dwyMNbskIYQPk6C+ABaL4sWxvckvKee3n2wm2N/O9UntzC5LCOGjpI36AtmtFl69NYV+sWE8tmA9S7ZK16hCiKYhQX0RnHYrM+9KpUebYKbMWcfyHdlmlySE8EES1BcpyGln9j396BzpYvK7aazcddTskoQQPkaCuhGEBPjx3j396BgewD3vpLF6T47ZJQkhfIgEdSMJdzmYc+8A2oY4uXvWD6RlSCdOQojGIUHdiCKDHMydPIDWwU4mvv0D6/YfN7skIYQPkKBuZFHBTv49eQDhLj/uemsN6w/kml2SEMLL1SuolVIhSqn3lVLblFJblVIDm7owb9a6lZO5kwcQEmjntpmr+Xan/MAohLhw9T2jfgX4UmvdHUgEtjZdSb6hbYg/C+4fSLsQfya+vYaPfsw0uyQhhJc6b1ArpVoBlwJvAWity7TW8vd8PbRp5c+CBwaSGhvK1PnreX3ZbunISQjRYPU5o44DsoG3lVI/KqVmKqUCm7gun9HK3847k/pxXWJbXvxyG7/7dIt0kSqEaJD6BLUNSAFe11onA4XAr89cSCl1n1IqTSmVlp0td+jV5LBZeXl8EpOHxjFrZQYPzV0nDx8QQtRbfYI6E8jUWq92v38fI7hPo7V+U2udqrVOjYyMbMwafYLFovi/axJ45poefLHxMHe+tYbcInmslxDi/M4b1Frrw8ABpVS8e9LlwJYmrcqH3Tu0E3+fkEz6gVzGvL6S/TlFZpckhPBw9b3q4yFgjlJqA5AE/L+mK8n3XZvYlvfu7U/OiTJufO070uVaayHEOdQrqLXW6e5mjd5a6xu01nLL3UXqFxfGhz8fRKDDxvg3Vsnle0KIOsmdiSbqHOnio58PIql9CFPnr+d3n26mvLLK7LKEEB5Ggtpk4S4H793bn7sHx/L2dxncPnM1R/JLzC5LCOFBJKg9gN1q4dlrL+GlmxNZn5nLyFdW8D95CIEQwk2C2oOMSYnh018MIcLl4K5/reGPi7ZKU4gQQoLa03SNDuI/vxjMhH4deON/exj/xioyj8slfEK0ZBLUHshpt/LHMb149dZkdmadYNQrK1i8+bDZZQkhTCJB7cFG927LZw8PoWN4IPfPXsvTH22kqKzC7LKEEM1MgtrDdQwP5IMpg7j/0k7MXbOfa6Z/y4/y5BghWhQJai/gZ7Pw1KgezJ08gLKKKsb+cxUvfbWdsgr5oVGIlkCC2osM6BTOokeHcn1SW6b/dxc3vvYd2w8XmF2WEKKJSVB7mWCnnZduTuKNO/pwOK+Ea//+LX9fspPSCuk2VQhfJUHtpa6+pDWLp17KlQnR/PXrHYx6ZQWrdueYXZYQoglIUHuxCJeDf9yWwtt396WssooJM77nsQXrOVYo/VwL4UskqH3A8Pgovnr0Mh4c3pn/pB/k8r8u4/21mfJ8RiF8hAS1j/D3s/LE1d354pGhdIp08fjC9Yx/43s2HcwzuzQhxEWSoPYx3aKDWHj/QP44phe7s09w7avf8sTC9dIjnxBeTILaB1ksign9OrD0iWFMHtqJj9MPctlflvHXr7ZTUFJudnlCiAZSTdGOmZqaqtPS0hp9u+LC7MspZNpXO/h0/SFCA+w8OLwLtw/oiNNuNbs0IYSbUmqt1jq11nkS1C3Hxsw8/rx4Gyt2HqV1sJNf/KwLN6e2x88mf1gJYTYJanGa7/fkMG3xdtL2HScm1J9HLu/KjcntsFklsIUwy7mCWv7PbIEGdApn4QMDefvuvoQG+PHE+xu46m/L+fjHg/KgAiE8kJxRt3Baa77aksVLX+1ge1YBbVs5mTQkjvF92xPktJtdnhAthjR9iPOqqtIs3X6EN5fvYfXeYwQ5bdw9KJa7B8cRGuhndnlC+DwJatEg6w/k8vqy3Xy5+TABflZuH9CROwd2JCY0wOzShPBZEtTiguzIKuAfS3fx2Yaf0FpzZUI0dw2KZWCncJRSZpcnhE+RoBYX5VBuMe99v4+5a/ZzvKicLlEubuvfgTEpMbTyl3ZsIRqDBLVoFCXllXy6/hDvrd7P+gO5OO0WrkxozQ1Jbbm0WyR2ubxPiAsmQS0a3aaDecz/4QCfbTjE8aJywgL9GJPcjgn9O9A50mV2eUJ4HQlq0WTKK6tYviOb99dm8vWWLCqqNP3jwhiT0o6rL2lNSIBcMSJEfUhQi2aRXVDK+2szmf/DfjJyirBbFUO7RjKiZ2uu6BFNmFzmJ0SdJKhFs9Jas+lgPp9uOMTnG37iYG4xFgV9Y8O4MiGaqxJa0yFcLvUToiYJamEarTWbD+WzePNhvtqcxfYs46np3aJdXNEjmisSokmKCcFikcv9RMsmQS08xv6cIr7ZmsXXW7JYk3GMyipNhMuPy7pFcVl8JEO7RMidkKJFkqAWHimvqJxlO47wzdYjLN+RTV5xOUpB75gQhnaJYEjXCFI6hEo3rKJFkKAWHq+ySrM+M5flO7JZsfMo6QdyqazSOO0W+nQMZUBcOAM6h5MYEyLBLXySBLXwOvkl5azancOq3Tms3nuMbYfz0RqcdgupHcPoHxdGcodQerdvRbD08id8gAS18Hq5RWWs3nusOrxP/iipFHSNctGnYxh9Y0Pp0zGUDmEB0heJ8DqNEtRKKSuQBhzUWo8+17IS1KKp5RWXs/5ALukHclm77zjr9h+noKQCgFb+dnq2C6Zn21Z0iw6iW3QQXaJc+PvJMyKF5zpXUNsasJ1HgK1AcKNUJcRFaOVv59JukVzaLRIw2rh3Hilg3b5cNh7MY+PBXP713V7KK40TEaWgc6SLnm2D6dmuFQltgunRJliuMBFeoV5BrZSKAa4BXgB+2aQVCXEBrBZF99bBdG996jyivLKKfTmF7Mw6wbbDBWw+lMf3e47xcfqh6mWigx10iXLROdJFp4hAukQF0TXaRVSQQ5pPhMeo7xn1y8CTQFBdCyil7gPuA+jQocOFVbPzG4jqAa3aXdj6QtRgt1roEhVEl6ggRvZqUz396IlStv6Uz9af8tn2UwG7s0/w0bqDFJRWVC8T5LTROdJVHeKdIwPpEuWiQ1iAPARYNLvztlErpUYDo7TWP1dKDQMeb5I26qJj8HJvaN0T7voMrA1plRHi4mityS4oZdeRE+zKPsHOrBPszj7BriMnOFJQWr2c3apoHxpA+7AAOoQF0D7Mn5jQAGJC/WkX4k9YoJ+ciYsLcrFt1IOB65RSowAnEKyUek9rfXtjFklAGIx+CT6cDEtfgCuebdTNC3EuSimigp1EBTsZ1CXitHn5JeXsyS5ktzvE9+cUse9Y4Wk/YJ7ksFloF+JPmxAn0cFOWgc7ad3q1Os2rZyEuxxY5ZZ50QANujyvSc+oT/rkYVj3Dtz2AXS94sK2IUQzySsu5+DxYjKPF3Eot5iDucUcyi3hUF4xWXklZBWUUll1+v9jVosiKshBdLCTCJcfYYF+hLscRAc5jC+LIAcRLgdhLj+CHDY5Q28hGuuqj+Yx8kXITIOP7oP7V0h7tfBorfzttPK3k9C29ouhKqs0OSdKOZxfwuG8ErLyS9yvSzlSUMLB3BI2Hswj50QZFVVnnzT5WS2EBNgJDfAjJMBOWKA72AP9CAnwIzTQToi/H8H+NoKcdoKcNoKddgL8rBLwPsQzb3g5uhPeHAate0l7tWgRqqo0x4vKyMo3AvxYYRk5J8rIKSwjt6iM40VlHC8q51hhGccKjffn+l/XblUEO40vkWD3EOS0EWC3Euiw4XLYCPY3Qt3ltOFvt+J0Dy6HjQA/Y+xy2uQRa83Eu86oASK6wui/Ge3V//sT/OwZsysSoklZLIpwl4Nwl4OEetyqUFmlyS8uJ7e4nONFZeQXl1NQUkF+iTHOKy4nr7icfPc4r6iMg8eLKCqrpLC0ghOlFdRyAl8rp91CkNOOy2Ej0GElwG7DblPYrRbsVgsOm6U66B02C342Cw6bFX8/CwF+RugH+Nmq13fYrNisCqtF4We1uL8gjPXsFot0eVsLzwxqgN43w97/wfJp0HEwdB5udkVCeAyrRREa6EdooB9xBDZ4fa01hWWV5BeXc6K0gpLySkrKqygqq6CwtJLCsgpOlBiBXlBiLHOi1Aj5wtIKSsqrOFFSQVmlprSikpKySkoqqigtr6S0oqrWZpyG7JvdanwR+FndAW61nJpmM6affO2wWbDbLFiVEf4WpfBzf5HYLBZsVmOazaKwWU+OLVgUWNzNQ0671f2FYnyRnPw8q0WhlKpe9uT2rRaF1WJMU0qhatTePqzxH4rhuUENMPLPcOAH+PA+mPIduKLMrkgIn6CUMpo2HE0TARWVVRSXV1JcVklh2amALyyroKxCU1mlqaiqoqyi6vSAr9SUV1ZRXllFWaUxv8wd/CffV8+vqKKoqILSCmPZqipNlTb+2ji5THml8VknP+8ivj/qJcLlIO2Zxr8IwrOD2i8Qxs2CGcPhg3vg9o+kvVoIL2CzWgiyGk0mnqSqSlNRI7S11lRVQWlFJUVlxlBW44ugskqj3etVaSPwjTFUam2sX+PHAoetafqT8fzUi06Aa/4K/3kQlj4PVzxndkVCCC9lsSj8LAo/zvyB1LO+UM7kHT/nJt8OfSbCt3+DrZ+aXY0QQjQr7whqMNqr26bAR1Pg6C6zqxFCiGbjPUFtc8DN74LND+bdCsW5ZlckhBDNwnuCGiCkvRHWx/bAwolQWW52RUII0eS8K6gBYofAtS/DnqWw6EnOeXuWEEL4AM+/6qM2ybfD0R3w3SsQ3hUG/tzsioQQosl4Z1ADXP4c5OyGxU9DcFu45AazKxJCiCbhfU0fJ1ksMGYGxPQ1+gTJ+NbsioQQokl4b1AD+AXArfMhNBbm3gpZm82uSAghGp13BzUYT4a5/QMjtN+7ybgiRAghfIj3BzVASAe4/UOoKIF3roe8TLMrEkKIRuMbQQ1GnyB3fAQlufDOtVBw2OyKhBCiUfhOUAO0TYbb3oeCLHj3ejhxxOyKhBDiovlWUAN06G/8wJi7H2ZdA/k/mV2REEJcFN8LaoC4ocYPjPmHYNYoabMWQng13wxqgI6DjB8YC4/C26Pg2F6zKxJCiAviu0ENRjPInR9DaT7862o4vMnsioQQosF8O6gB2vWBu78Ei804s9630uyKhBCiQXw/qAGiusOkxcbDcWffCFs+MbsiIYSot5YR1GD0ZT3pS2jdCxbcCav+IV2kCiG8QssJaoDACLjrU+hxrdHr3qInobLC7KqEEOKcWlZQA9j9Ydw7MPAXsOZNmDseSvLMrkoIIerU8oIajC5Sr34BRr8Me5bBzCulMychhMdqmUF9UurdRv8ghUdgxs9g91KzKxJCiLO07KAGiLsU7l0CrmjjipDlf4GqKrOrEkKIahLUAOGdjbDueRP893mYNwGKj5tdlRBCABLUpzhccNNMGPkX2LUE/jkU9n9vdlVCCCFBfRqloP99cM9isFiNOxn/9xeoqjS7MiFECyZBXZt2feD+FdBzDCx93uguVa4KEUKYRIK6Ls5g4ynnN74BWVvg9cHww0y5m1EI0ewkqM9FKUi8BX6+Etr3h88fM54cI12mCiGa0XmDWinVXim1VBH/nY0AAAqrSURBVCm1RSm1WSn1SHMU5lFaxRjXW1/zEhxcB68PglWvSdu1EKJZ1OeMugJ4TGudAAwAHlRKJTRtWR5IKeh7Dzz4PXQcDIufgplXwKF0sysTQvi48wa11vonrfU69+sCYCvQrqkL81itYuC2hTBmJuQdgBnDYdGvoCTf7MqEED6qQW3USqlYIBlYXcu8+5RSaUqptOzs7MapzlMpBb3HwS/SIHUSrH4D/p4Ca9+R5hAhRKOrd1ArpVzAB8CjWuuzTh+11m9qrVO11qmRkZGNWaPn8g+Ba/4K9y2F8C7w6cPwxmVGR09CCNFI6hXUSik7RkjP0Vp/2LQleaG2yXD3Ihg3y+gy9d3rYfYYOLzR7MqEED6gPld9KOAtYKvW+qWmL8lLKQWX3Ai/+AGueh4OrjVuQ//wPrlZRghxUepzRj0YuAP4mVIq3T2MauK6vJfdCYMegkfSYfDDxvMZ/54KnzwMuQfMrk4I4YWUboI77VJTU3VaWlqjb9crFRyGFS/B2reNuxp7j4fBj0BkN7MrE0J4EKXUWq11am3z5M7EphbUGkb9GR5aZ1whsukD+Ec/mHcbHFhjdnVCCC8gQd1cQtobgf3oRhj6GGR8C29dCW9dZTSPyEN2hRB1kKBubq5IuPw3MHUzjPwzFPwEC+6A6Unw7d+gMMfsCoUQHkbaqM1WWQE7Fhk3zWSsAKsDEq6DlDuh4xDjQbxCCJ93rjZqW3MXI85gtUGPa43hyFZI+xdsmA8bF0JoHCTdavwAGdrR7EqFECaRM2pPVF4MWz+Fde8aZ9kAsUOh11jocR0EhJlbnxCi0Z3rjFqC2tPl7of182H9XDi2Gyw26PwzSLgB4kdKaAvhIySofYHW8NN64/K+zR8ZPfcpK8QNhe6jjdBuFWN2lUKICyRB7Wu0hkM/Gs0jWz+BnF3G9Na9odvV0OVK47mPVvkJQghvIUHt647uhO1fwPZFcGA16CpwhkCny6DTMGMI62RujUKIc5KgbkmKj8PupbDrG6O71fyDxvRW7Y0n08QOgY6DjOBWytRShRCnyOV5LYl/KPQcYwxaG80ie5YZV4/s+ho2zDOWC4w0Htgb0xdiUo2uWv0CTS1dCFE7CWpfphREdDWGfpON4M7eBvu/N5pI9n8P2z5zL2uFqB7QNskI7TbJEJ0Adn9z90EIIU0fLV7hUaPv7MwfjB8oD66D4mPGPGWFiG7QupcR2lGXGOPgdtJsIkQjk6YPUbfACONKkW5XG++1Ni79O5RuPKHm8AbY9x1sXHBqHb8g4yw9Mt54BNnJITQWHC5TdkMIXyZBLU6nFIR0MIaE605NLz5u3OKetRmO7oDs7Ubb9/q5p68fGGkEdmgchMUZ45D2xjXeQW3B5teceyOET5CgFvXjH2pcLdJx0OnTS08YjxrL2QXH98LxDDi2F/avMvoroWbTmgJXNAS3NYagNkZ/3UFtICjamOeKhoBwsFibceeE8GwS1OLiOFzQprcxnKmizLgFPu+AcZlgrnucf8gI9oxvoSS3lo0qI6xdUcY4MMIYB4SDf5jxpREQZlwr7h9qPA3eESxn68JnSVCLpmPzg4guxlCX8mLjcWUnjsCJLGMozDbeF2ZDUQ4c3mSMi49z+hn6mZ/nD85W4AgCZ7AxdgQZbeoOF/i5jEsQ/VzgFwD2AON9zbHdv8bY3+hbRX44FSaToBbmsvsbbdlhcedftqoSSvKg6JhxZUpxrhHexcehNN+YV5IHpQXG+9ICKMiCshPG67ITUNXAJ+koi/EFYHeC7eTgAKvfGWOH8cVksRvTrO6xzc8YW+zuaXbjtcVm3OJvsZ16b7HWPlbW018rZbw/OV1Z3K8tp14ryxmDqn0a6uxlUO7X8gXlKSSohfewWI0mj4vpMbCiFMoKjaG8qMa4yAjyihLjLL+8GCqKobzk1LSKUmNaRSlUlp0aFxWeel9VbjwMotI9r7LcmK4rG++/Q7NSZwS6OmNabfPOXM89rt6kqmP76tS06uVUHetw+rJnlX2OdWtd9lz7Xpda9sk/DCYtOsc6F0aCWrQsNocxNHf3sFVV7hAvN8ZVle7XFTWGSve43Fheu5fRle55lcZrXVXL66qzX5+cr/UZ45PzNFBznvs1usa8M6bVNh/OMa/GMsaCNV6esVz1NPdy+hzrnLbsmfTp2zlt3TqWPTOQa35OrR9Rxz45W9W9zkWQoBaiOVgsYHF/SQjRQPJAPiGE8HAS1EII4eEkqIUQwsNJUAshhIeToBZCCA8nQS2EEB5OgloIITycBLUQQni4JnnCi1IqG9h3gatHAEcbsRxv0BL3GVrmfrfEfYaWud8N3eeOWuvI2mY0SVBfDKVUWl2Po/FVLXGfoWXud0vcZ2iZ+92Y+yxNH0II4eEkqIUQwsN5YlC/aXYBJmiJ+wwtc79b4j5Dy9zvRttnj2ujFkIIcTpPPKMWQghRgwS1EEJ4OI8JaqXUCKXUdqXULqXUr82up6kopdorpZYqpbYopTYrpR5xTw9TSn2tlNrpHoeaXWtjU0pZlVI/KqU+c7+PU0qtdh/z+Uopn3uMuFIqRCn1vlJqm1Jqq1JqoK8fa6XUVPe/7U1KqblKKacvHmul1L+UUkeUUptqTKv12CrDdPf+b1BKpTTkszwiqJVSVuAfwEggAZiglEowt6omUwE8prVOAAYAD7r39dfAEq11V2CJ+72veQTYWuP9i8DftNZdgOPAPaZU1bReAb7UWncHEjH232ePtVKqHfAwkKq17glYgVvwzWM9CxhxxrS6ju1IoKt7uA94vUGfpLU2fQAGAotrvH8KeMrsuppp3/8DXAlsB9q4p7UBtptdWyPvZ4z7H+7PgM8wngx6FLDV9m/AFwagFbAX94/2Nab77LEG2gEHgDCMR/19Blztq8caiAU2ne/YAm8AE2pbrj6DR5xRc+rgnpTpnubTlFKxQDKwGojWWv/knnUYiDaprKbyMvAkUOV+Hw7kaq0r3O998ZjHAdnA2+4mn5lKqUB8+FhrrQ8C04D9wE9AHrAW3z/WJ9V1bC8q4zwlqFscpZQL+AB4VGudX3OeNr5yfea6SaXUaOCI1nqt2bU0MxuQAryutU4GCjmjmcMHj3UocD3Gl1RbIJCzmwdahMY8tp4S1AeB9jXex7in+SSllB0jpOdorT90T85SSrVxz28DHDGrviYwGLhOKZUBzMNo/ngFCFFK2dzL+OIxzwQytdar3e/fxwhuXz7WVwB7tdbZWuty4EOM4+/rx/qkuo7tRWWcpwT1D0BX9y/Dfhg/Pnxick1NQimlgLeArVrrl2rM+gS4y/36Loy2a5+gtX5Kax2jtY7FOLb/1VrfBiwFxroX86l9BtBaHwYOKKXi3ZMuB7bgw8cao8ljgFIqwP1v/eQ++/SxrqGuY/sJcKf76o8BQF6NJpLzM7sxvkbj+ihgB7Ab+D+z62nC/RyC8efQBiDdPYzCaLNdAuwEvgHCzK61ifZ/GPCZ+3UnYA2wC1gIOMyurwn2NwlIcx/vj4FQXz/WwO+AbcAmYDbg8MVjDczFaIcvx/jr6Z66ji3Gj+f/cOfbRoyrYur9WXILuRBCeDhPafoQQghRBwlqIYTwcBLUQgjh4SSohRDCw0lQCyGEh5OgFkIIDydBLYQQHu7/AzS6ASTqiYNUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uNRWt8J-D3x",
        "outputId": "ae18c84d-0048-4145-da9e-2575150b13bc"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction).mul(scaler_y), validation_volatility)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f899f24b0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.023669748462590318"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMhCe4OT-IRv"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256,input_shape=[window_size],activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=validation_dataset, verbose=0)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "utcEObNh-sTL",
        "outputId": "25b825cf-6307-43a0-f0d3-fd23a78e446b"
      },
      "source": [
        "plt.plot(history.history['val_mse'],label='Validation MSE')\n",
        "plt.plot(history.history['mse'],label='Training MSE')\n",
        "plt.legend()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f899f0fcdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPB97jyE-5ig",
        "outputId": "fa9d1528-7287-4832-ead1-0becdb0f1631"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction).mul(scaler_y), validation_volatility)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f899f052680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.023475703402842094"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTpGkVWS-8iW"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=validation_dataset, verbose=0)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xJUk7Rlh_KKS",
        "outputId": "e6fe7b9c-b2ae-44a6-9658-7d7a5f2b6d4e"
      },
      "source": [
        "plt.plot(history.history['val_mse'],label='Validation MSE')\n",
        "plt.plot(history.history['mse'],label='Training MSE')\n",
        "plt.legend()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f899f015390>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qudk5Bcv_OfV",
        "outputId": "03601d0f-17ba-406c-8f04-1cd5405a8b70"
      },
      "source": [
        "prediction = model.predict(validation_x)\n",
        "calculate_error_rmse(pd.DataFrame(prediction).mul(scaler_y), validation_volatility)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02351698303418633"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou-DlAp7By24"
      },
      "source": [
        "## Add in Squared-Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r7KmM1w_SVs"
      },
      "source": [
        "window_size = forward_window\n",
        "batch_size = 32\n",
        "shuffle_buffer=1000\n",
        "\n",
        "train_x = rolling(weekly_data_returns.WILL5000IND_Ret[training_dates].values, window_size)\n",
        "scaler_x = train_x.std()\n",
        "train_x = train_x / scaler_x\n",
        "scaler_x2 = (train_x**2).std()\n",
        "train_x2 = (train_x**2) / scaler_x2\n",
        "train_y = training_volatility.WILL5000IND_Ret_Realized_Vol.values[window_size-1:][:,None]\n",
        "scaler_y = train_y.std()\n",
        "train_y = train_y / scaler_y\n",
        "\n",
        "train_data = np.hstack((train_x,train_x2,train_y))\n",
        "\n",
        "validation_x = rolling(weekly_data_returns[weekly_data_returns.index <= validation_dates[-1]].WILL5000IND_Ret.values, window_size)[-len(validation_dates):]\n",
        "validation_y = validation_volatility.WILL5000IND_Ret_Realized_Vol.values[:,None]\n",
        "validation_x = validation_x / scaler_x\n",
        "validation_x2 = (validation_x**2) / scaler_x2\n",
        "validation_y = validation_y / scaler_y\n",
        "validation_data = np.hstack((validation_x,validation_x2,validation_y))\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "train_dataset = train_dataset.shuffle(shuffle_buffer)\n",
        "train_dataset = train_dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_data)\n",
        "validation_dataset = validation_dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "validation_dataset = validation_dataset.batch(batch_size).prefetch(1)\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWs55CtnFMEu",
        "outputId": "4549f999-260f-4fd9-fed0-b7434d87b142"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256,activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mse\"])\n",
        "history = model.fit(train_dataset, epochs=500, validation_data=validation_dataset, verbose=1)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 3.8898 - mse: 3.8898 - val_loss: 8.9094 - val_mse: 8.9094\n",
            "Epoch 2/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.5167 - mse: 3.5167 - val_loss: 8.3123 - val_mse: 8.3123\n",
            "Epoch 3/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.3497 - mse: 3.3497 - val_loss: 7.7378 - val_mse: 7.7378\n",
            "Epoch 4/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.0663 - mse: 3.0663 - val_loss: 7.2697 - val_mse: 7.2697\n",
            "Epoch 5/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8674 - mse: 2.8674 - val_loss: 6.8824 - val_mse: 6.8824\n",
            "Epoch 6/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.7246 - mse: 2.7246 - val_loss: 6.5365 - val_mse: 6.5365\n",
            "Epoch 7/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.5637 - mse: 2.5637 - val_loss: 6.2510 - val_mse: 6.2510\n",
            "Epoch 8/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.3874 - mse: 2.3874 - val_loss: 6.0165 - val_mse: 6.0165\n",
            "Epoch 9/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.2843 - mse: 2.2843 - val_loss: 5.8183 - val_mse: 5.8183\n",
            "Epoch 10/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.1888 - mse: 2.1888 - val_loss: 5.6524 - val_mse: 5.6524\n",
            "Epoch 11/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.0675 - mse: 2.0675 - val_loss: 5.5098 - val_mse: 5.5098\n",
            "Epoch 12/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9932 - mse: 1.9932 - val_loss: 5.3948 - val_mse: 5.3948\n",
            "Epoch 13/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.9240 - mse: 1.9240 - val_loss: 5.3009 - val_mse: 5.3009\n",
            "Epoch 14/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.8390 - mse: 1.8390 - val_loss: 5.2259 - val_mse: 5.2259\n",
            "Epoch 15/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.7433 - mse: 1.7433 - val_loss: 5.1610 - val_mse: 5.1610\n",
            "Epoch 16/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.6996 - mse: 1.6996 - val_loss: 5.1089 - val_mse: 5.1089\n",
            "Epoch 17/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.6731 - mse: 1.6731 - val_loss: 5.0688 - val_mse: 5.0688\n",
            "Epoch 18/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.6054 - mse: 1.6054 - val_loss: 5.0382 - val_mse: 5.0382\n",
            "Epoch 19/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.5762 - mse: 1.5762 - val_loss: 5.0133 - val_mse: 5.0133\n",
            "Epoch 20/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.5193 - mse: 1.5193 - val_loss: 4.9957 - val_mse: 4.9957\n",
            "Epoch 21/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.5009 - mse: 1.5009 - val_loss: 4.9852 - val_mse: 4.9852\n",
            "Epoch 22/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.4778 - mse: 1.4778 - val_loss: 4.9734 - val_mse: 4.9734\n",
            "Epoch 23/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.4648 - mse: 1.4648 - val_loss: 4.9645 - val_mse: 4.9645\n",
            "Epoch 24/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.4052 - mse: 1.4052 - val_loss: 4.9595 - val_mse: 4.9595\n",
            "Epoch 25/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.3899 - mse: 1.3899 - val_loss: 4.9564 - val_mse: 4.9564\n",
            "Epoch 26/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.3775 - mse: 1.3775 - val_loss: 4.9539 - val_mse: 4.9539\n",
            "Epoch 27/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.3834 - mse: 1.3834 - val_loss: 4.9491 - val_mse: 4.9491\n",
            "Epoch 28/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.3101 - mse: 1.3101 - val_loss: 4.9488 - val_mse: 4.9488\n",
            "Epoch 29/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.3425 - mse: 1.3425 - val_loss: 4.9443 - val_mse: 4.9443\n",
            "Epoch 30/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2844 - mse: 1.2844 - val_loss: 4.9457 - val_mse: 4.9457\n",
            "Epoch 31/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2621 - mse: 1.2621 - val_loss: 4.9511 - val_mse: 4.9511\n",
            "Epoch 32/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.2697 - mse: 1.2697 - val_loss: 4.9524 - val_mse: 4.9524\n",
            "Epoch 33/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.2691 - mse: 1.2691 - val_loss: 4.9506 - val_mse: 4.9506\n",
            "Epoch 34/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2318 - mse: 1.2318 - val_loss: 4.9447 - val_mse: 4.9447\n",
            "Epoch 35/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2175 - mse: 1.2175 - val_loss: 4.9489 - val_mse: 4.9489\n",
            "Epoch 36/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.2457 - mse: 1.2457 - val_loss: 4.9399 - val_mse: 4.9399\n",
            "Epoch 37/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2330 - mse: 1.2330 - val_loss: 4.9378 - val_mse: 4.9378\n",
            "Epoch 38/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2301 - mse: 1.2301 - val_loss: 4.9369 - val_mse: 4.9369\n",
            "Epoch 39/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1837 - mse: 1.1837 - val_loss: 4.9308 - val_mse: 4.9308\n",
            "Epoch 40/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2047 - mse: 1.2047 - val_loss: 4.9258 - val_mse: 4.9258\n",
            "Epoch 41/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1494 - mse: 1.1494 - val_loss: 4.9257 - val_mse: 4.9257\n",
            "Epoch 42/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1643 - mse: 1.1643 - val_loss: 4.9223 - val_mse: 4.9223\n",
            "Epoch 43/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1656 - mse: 1.1656 - val_loss: 4.9183 - val_mse: 4.9183\n",
            "Epoch 44/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1440 - mse: 1.1440 - val_loss: 4.9076 - val_mse: 4.9076\n",
            "Epoch 45/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1330 - mse: 1.1330 - val_loss: 4.9029 - val_mse: 4.9029\n",
            "Epoch 46/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1289 - mse: 1.1289 - val_loss: 4.8996 - val_mse: 4.8996\n",
            "Epoch 47/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1295 - mse: 1.1295 - val_loss: 4.8922 - val_mse: 4.8922\n",
            "Epoch 48/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1381 - mse: 1.1381 - val_loss: 4.8713 - val_mse: 4.8713\n",
            "Epoch 49/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1749 - mse: 1.1749 - val_loss: 4.8555 - val_mse: 4.8555\n",
            "Epoch 50/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0850 - mse: 1.0850 - val_loss: 4.8546 - val_mse: 4.8546\n",
            "Epoch 51/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.1152 - mse: 1.1152 - val_loss: 4.8291 - val_mse: 4.8291\n",
            "Epoch 52/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0856 - mse: 1.0856 - val_loss: 4.8224 - val_mse: 4.8224\n",
            "Epoch 53/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1096 - mse: 1.1096 - val_loss: 4.8104 - val_mse: 4.8104\n",
            "Epoch 54/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0462 - mse: 1.0462 - val_loss: 4.7986 - val_mse: 4.7986\n",
            "Epoch 55/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0761 - mse: 1.0761 - val_loss: 4.7906 - val_mse: 4.7906\n",
            "Epoch 56/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0669 - mse: 1.0669 - val_loss: 4.7755 - val_mse: 4.7755\n",
            "Epoch 57/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0606 - mse: 1.0606 - val_loss: 4.7615 - val_mse: 4.7615\n",
            "Epoch 58/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0239 - mse: 1.0239 - val_loss: 4.7588 - val_mse: 4.7588\n",
            "Epoch 59/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0284 - mse: 1.0284 - val_loss: 4.7506 - val_mse: 4.7506\n",
            "Epoch 60/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0267 - mse: 1.0267 - val_loss: 4.7401 - val_mse: 4.7401\n",
            "Epoch 61/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0518 - mse: 1.0518 - val_loss: 4.7346 - val_mse: 4.7346\n",
            "Epoch 62/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0332 - mse: 1.0332 - val_loss: 4.7235 - val_mse: 4.7235\n",
            "Epoch 63/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0593 - mse: 1.0593 - val_loss: 4.7148 - val_mse: 4.7148\n",
            "Epoch 64/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0380 - mse: 1.0380 - val_loss: 4.6898 - val_mse: 4.6898\n",
            "Epoch 65/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9743 - mse: 0.9743 - val_loss: 4.6862 - val_mse: 4.6862\n",
            "Epoch 66/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0103 - mse: 1.0103 - val_loss: 4.6760 - val_mse: 4.6760\n",
            "Epoch 67/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0119 - mse: 1.0119 - val_loss: 4.6601 - val_mse: 4.6601\n",
            "Epoch 68/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9827 - mse: 0.9827 - val_loss: 4.6502 - val_mse: 4.6502\n",
            "Epoch 69/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0162 - mse: 1.0162 - val_loss: 4.6439 - val_mse: 4.6439\n",
            "Epoch 70/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0281 - mse: 1.0281 - val_loss: 4.6247 - val_mse: 4.6247\n",
            "Epoch 71/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9999 - mse: 0.9999 - val_loss: 4.6027 - val_mse: 4.6027\n",
            "Epoch 72/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0460 - mse: 1.0460 - val_loss: 4.5871 - val_mse: 4.5871\n",
            "Epoch 73/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9922 - mse: 0.9922 - val_loss: 4.5738 - val_mse: 4.5738\n",
            "Epoch 74/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0364 - mse: 1.0364 - val_loss: 4.5461 - val_mse: 4.5461\n",
            "Epoch 75/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0053 - mse: 1.0053 - val_loss: 4.5301 - val_mse: 4.5301\n",
            "Epoch 76/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9874 - mse: 0.9874 - val_loss: 4.5261 - val_mse: 4.5261\n",
            "Epoch 77/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 4.5048 - val_mse: 4.5048\n",
            "Epoch 78/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9868 - mse: 0.9868 - val_loss: 4.4796 - val_mse: 4.4796\n",
            "Epoch 79/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9919 - mse: 0.9919 - val_loss: 4.4625 - val_mse: 4.4625\n",
            "Epoch 80/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9819 - mse: 0.9819 - val_loss: 4.4583 - val_mse: 4.4583\n",
            "Epoch 81/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0036 - mse: 1.0036 - val_loss: 4.4343 - val_mse: 4.4343\n",
            "Epoch 82/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9933 - mse: 0.9933 - val_loss: 4.4212 - val_mse: 4.4212\n",
            "Epoch 83/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9381 - mse: 0.9381 - val_loss: 4.4124 - val_mse: 4.4124\n",
            "Epoch 84/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9646 - mse: 0.9646 - val_loss: 4.3962 - val_mse: 4.3962\n",
            "Epoch 85/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9393 - mse: 0.9393 - val_loss: 4.3963 - val_mse: 4.3963\n",
            "Epoch 86/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9579 - mse: 0.9579 - val_loss: 4.3800 - val_mse: 4.3800\n",
            "Epoch 87/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9730 - mse: 0.9730 - val_loss: 4.3627 - val_mse: 4.3627\n",
            "Epoch 88/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9329 - mse: 0.9329 - val_loss: 4.3512 - val_mse: 4.3512\n",
            "Epoch 89/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9283 - mse: 0.9283 - val_loss: 4.3477 - val_mse: 4.3477\n",
            "Epoch 90/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9445 - mse: 0.9445 - val_loss: 4.3406 - val_mse: 4.3406\n",
            "Epoch 91/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9267 - mse: 0.9267 - val_loss: 4.3322 - val_mse: 4.3322\n",
            "Epoch 92/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9352 - mse: 0.9352 - val_loss: 4.3180 - val_mse: 4.3180\n",
            "Epoch 93/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9560 - mse: 0.9560 - val_loss: 4.3090 - val_mse: 4.3090\n",
            "Epoch 94/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9589 - mse: 0.9589 - val_loss: 4.2936 - val_mse: 4.2936\n",
            "Epoch 95/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9297 - mse: 0.9297 - val_loss: 4.2815 - val_mse: 4.2815\n",
            "Epoch 96/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9232 - mse: 0.9232 - val_loss: 4.2677 - val_mse: 4.2677\n",
            "Epoch 97/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9049 - mse: 0.9049 - val_loss: 4.2541 - val_mse: 4.2541\n",
            "Epoch 98/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9076 - mse: 0.9076 - val_loss: 4.2470 - val_mse: 4.2470\n",
            "Epoch 99/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9023 - mse: 0.9023 - val_loss: 4.2389 - val_mse: 4.2389\n",
            "Epoch 100/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8913 - mse: 0.8913 - val_loss: 4.2321 - val_mse: 4.2321\n",
            "Epoch 101/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9471 - mse: 0.9471 - val_loss: 4.2264 - val_mse: 4.2264\n",
            "Epoch 102/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8919 - mse: 0.8919 - val_loss: 4.2080 - val_mse: 4.2080\n",
            "Epoch 103/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9316 - mse: 0.9316 - val_loss: 4.1963 - val_mse: 4.1963\n",
            "Epoch 104/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8769 - mse: 0.8769 - val_loss: 4.1841 - val_mse: 4.1841\n",
            "Epoch 105/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9076 - mse: 0.9076 - val_loss: 4.1833 - val_mse: 4.1833\n",
            "Epoch 106/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8958 - mse: 0.8958 - val_loss: 4.1742 - val_mse: 4.1742\n",
            "Epoch 107/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9181 - mse: 0.9181 - val_loss: 4.1621 - val_mse: 4.1621\n",
            "Epoch 108/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8846 - mse: 0.8846 - val_loss: 4.1555 - val_mse: 4.1555\n",
            "Epoch 109/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8821 - mse: 0.8821 - val_loss: 4.1498 - val_mse: 4.1498\n",
            "Epoch 110/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8737 - mse: 0.8737 - val_loss: 4.1318 - val_mse: 4.1318\n",
            "Epoch 111/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8764 - mse: 0.8764 - val_loss: 4.1258 - val_mse: 4.1258\n",
            "Epoch 112/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8715 - mse: 0.8715 - val_loss: 4.1199 - val_mse: 4.1199\n",
            "Epoch 113/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8910 - mse: 0.8910 - val_loss: 4.1088 - val_mse: 4.1088\n",
            "Epoch 114/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8654 - mse: 0.8654 - val_loss: 4.0981 - val_mse: 4.0981\n",
            "Epoch 115/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8632 - mse: 0.8632 - val_loss: 4.0870 - val_mse: 4.0870\n",
            "Epoch 116/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9038 - mse: 0.9038 - val_loss: 4.0774 - val_mse: 4.0774\n",
            "Epoch 117/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8769 - mse: 0.8769 - val_loss: 4.0677 - val_mse: 4.0677\n",
            "Epoch 118/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8779 - mse: 0.8779 - val_loss: 4.0608 - val_mse: 4.0608\n",
            "Epoch 119/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8720 - mse: 0.8720 - val_loss: 4.0544 - val_mse: 4.0544\n",
            "Epoch 120/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8445 - mse: 0.8445 - val_loss: 4.0531 - val_mse: 4.0531\n",
            "Epoch 121/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8488 - mse: 0.8488 - val_loss: 4.0469 - val_mse: 4.0469\n",
            "Epoch 122/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8348 - mse: 0.8348 - val_loss: 4.0456 - val_mse: 4.0456\n",
            "Epoch 123/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8601 - mse: 0.8601 - val_loss: 4.0381 - val_mse: 4.0381\n",
            "Epoch 124/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8459 - mse: 0.8459 - val_loss: 4.0292 - val_mse: 4.0292\n",
            "Epoch 125/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8570 - mse: 0.8570 - val_loss: 4.0188 - val_mse: 4.0188\n",
            "Epoch 126/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8589 - mse: 0.8589 - val_loss: 4.0144 - val_mse: 4.0144\n",
            "Epoch 127/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8490 - mse: 0.8490 - val_loss: 4.0039 - val_mse: 4.0039\n",
            "Epoch 128/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8611 - mse: 0.8611 - val_loss: 3.9977 - val_mse: 3.9977\n",
            "Epoch 129/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8719 - mse: 0.8719 - val_loss: 3.9931 - val_mse: 3.9931\n",
            "Epoch 130/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8769 - mse: 0.8769 - val_loss: 3.9813 - val_mse: 3.9813\n",
            "Epoch 131/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8759 - mse: 0.8759 - val_loss: 3.9702 - val_mse: 3.9702\n",
            "Epoch 132/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8313 - mse: 0.8313 - val_loss: 3.9633 - val_mse: 3.9633\n",
            "Epoch 133/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8448 - mse: 0.8448 - val_loss: 3.9561 - val_mse: 3.9561\n",
            "Epoch 134/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8477 - mse: 0.8477 - val_loss: 3.9458 - val_mse: 3.9458\n",
            "Epoch 135/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8436 - mse: 0.8436 - val_loss: 3.9391 - val_mse: 3.9391\n",
            "Epoch 136/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8311 - mse: 0.8311 - val_loss: 3.9328 - val_mse: 3.9328\n",
            "Epoch 137/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8418 - mse: 0.8418 - val_loss: 3.9278 - val_mse: 3.9278\n",
            "Epoch 138/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8519 - mse: 0.8519 - val_loss: 3.9182 - val_mse: 3.9182\n",
            "Epoch 139/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8400 - mse: 0.8400 - val_loss: 3.9132 - val_mse: 3.9132\n",
            "Epoch 140/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8450 - mse: 0.8450 - val_loss: 3.9068 - val_mse: 3.9068\n",
            "Epoch 141/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8187 - mse: 0.8187 - val_loss: 3.9057 - val_mse: 3.9057\n",
            "Epoch 142/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8366 - mse: 0.8366 - val_loss: 3.9000 - val_mse: 3.9000\n",
            "Epoch 143/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8187 - mse: 0.8187 - val_loss: 3.8896 - val_mse: 3.8896\n",
            "Epoch 144/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8298 - mse: 0.8298 - val_loss: 3.8794 - val_mse: 3.8794\n",
            "Epoch 145/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8428 - mse: 0.8428 - val_loss: 3.8757 - val_mse: 3.8757\n",
            "Epoch 146/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8332 - mse: 0.8332 - val_loss: 3.8709 - val_mse: 3.8709\n",
            "Epoch 147/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8589 - mse: 0.8589 - val_loss: 3.8646 - val_mse: 3.8646\n",
            "Epoch 148/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8236 - mse: 0.8236 - val_loss: 3.8591 - val_mse: 3.8591\n",
            "Epoch 149/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8329 - mse: 0.8329 - val_loss: 3.8538 - val_mse: 3.8538\n",
            "Epoch 150/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8258 - mse: 0.8258 - val_loss: 3.8439 - val_mse: 3.8439\n",
            "Epoch 151/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8378 - mse: 0.8378 - val_loss: 3.8407 - val_mse: 3.8407\n",
            "Epoch 152/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8065 - mse: 0.8065 - val_loss: 3.8364 - val_mse: 3.8364\n",
            "Epoch 153/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8075 - mse: 0.8075 - val_loss: 3.8352 - val_mse: 3.8352\n",
            "Epoch 154/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8400 - mse: 0.8400 - val_loss: 3.8306 - val_mse: 3.8306\n",
            "Epoch 155/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8108 - mse: 0.8108 - val_loss: 3.8249 - val_mse: 3.8249\n",
            "Epoch 156/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8265 - mse: 0.8265 - val_loss: 3.8156 - val_mse: 3.8156\n",
            "Epoch 157/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8210 - mse: 0.8210 - val_loss: 3.8115 - val_mse: 3.8115\n",
            "Epoch 158/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8286 - mse: 0.8286 - val_loss: 3.8031 - val_mse: 3.8031\n",
            "Epoch 159/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8097 - mse: 0.8097 - val_loss: 3.8002 - val_mse: 3.8002\n",
            "Epoch 160/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7962 - mse: 0.7962 - val_loss: 3.8006 - val_mse: 3.8006\n",
            "Epoch 161/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8338 - mse: 0.8338 - val_loss: 3.7937 - val_mse: 3.7937\n",
            "Epoch 162/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8079 - mse: 0.8079 - val_loss: 3.7891 - val_mse: 3.7891\n",
            "Epoch 163/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8465 - mse: 0.8465 - val_loss: 3.7815 - val_mse: 3.7815\n",
            "Epoch 164/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7983 - mse: 0.7983 - val_loss: 3.7765 - val_mse: 3.7765\n",
            "Epoch 165/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8069 - mse: 0.8069 - val_loss: 3.7672 - val_mse: 3.7672\n",
            "Epoch 166/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8138 - mse: 0.8138 - val_loss: 3.7623 - val_mse: 3.7623\n",
            "Epoch 167/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8160 - mse: 0.8160 - val_loss: 3.7551 - val_mse: 3.7551\n",
            "Epoch 168/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7897 - mse: 0.7897 - val_loss: 3.7540 - val_mse: 3.7540\n",
            "Epoch 169/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7951 - mse: 0.7951 - val_loss: 3.7503 - val_mse: 3.7503\n",
            "Epoch 170/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8467 - mse: 0.8467 - val_loss: 3.7447 - val_mse: 3.7447\n",
            "Epoch 171/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7804 - mse: 0.7804 - val_loss: 3.7325 - val_mse: 3.7325\n",
            "Epoch 172/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8180 - mse: 0.8180 - val_loss: 3.7294 - val_mse: 3.7294\n",
            "Epoch 173/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7934 - mse: 0.7934 - val_loss: 3.7234 - val_mse: 3.7234\n",
            "Epoch 174/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7916 - mse: 0.7916 - val_loss: 3.7200 - val_mse: 3.7200\n",
            "Epoch 175/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8121 - mse: 0.8121 - val_loss: 3.7175 - val_mse: 3.7175\n",
            "Epoch 176/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8102 - mse: 0.8102 - val_loss: 3.7121 - val_mse: 3.7121\n",
            "Epoch 177/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8239 - mse: 0.8239 - val_loss: 3.7087 - val_mse: 3.7087\n",
            "Epoch 178/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7788 - mse: 0.7788 - val_loss: 3.7026 - val_mse: 3.7026\n",
            "Epoch 179/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7888 - mse: 0.7888 - val_loss: 3.7006 - val_mse: 3.7006\n",
            "Epoch 180/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8110 - mse: 0.8110 - val_loss: 3.6964 - val_mse: 3.6964\n",
            "Epoch 181/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7721 - mse: 0.7721 - val_loss: 3.6921 - val_mse: 3.6921\n",
            "Epoch 182/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8173 - mse: 0.8173 - val_loss: 3.6875 - val_mse: 3.6875\n",
            "Epoch 183/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7998 - mse: 0.7998 - val_loss: 3.6776 - val_mse: 3.6776\n",
            "Epoch 184/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7925 - mse: 0.7925 - val_loss: 3.6727 - val_mse: 3.6727\n",
            "Epoch 185/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7861 - mse: 0.7861 - val_loss: 3.6713 - val_mse: 3.6713\n",
            "Epoch 186/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7834 - mse: 0.7834 - val_loss: 3.6661 - val_mse: 3.6661\n",
            "Epoch 187/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7987 - mse: 0.7987 - val_loss: 3.6619 - val_mse: 3.6619\n",
            "Epoch 188/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7813 - mse: 0.7813 - val_loss: 3.6584 - val_mse: 3.6584\n",
            "Epoch 189/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7689 - mse: 0.7689 - val_loss: 3.6587 - val_mse: 3.6587\n",
            "Epoch 190/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7888 - mse: 0.7888 - val_loss: 3.6570 - val_mse: 3.6570\n",
            "Epoch 191/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7867 - mse: 0.7867 - val_loss: 3.6528 - val_mse: 3.6528\n",
            "Epoch 192/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7806 - mse: 0.7806 - val_loss: 3.6505 - val_mse: 3.6505\n",
            "Epoch 193/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7945 - mse: 0.7945 - val_loss: 3.6516 - val_mse: 3.6516\n",
            "Epoch 194/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7747 - mse: 0.7747 - val_loss: 3.6505 - val_mse: 3.6505\n",
            "Epoch 195/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7829 - mse: 0.7829 - val_loss: 3.6438 - val_mse: 3.6438\n",
            "Epoch 196/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7744 - mse: 0.7744 - val_loss: 3.6441 - val_mse: 3.6441\n",
            "Epoch 197/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7615 - mse: 0.7615 - val_loss: 3.6445 - val_mse: 3.6445\n",
            "Epoch 198/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7891 - mse: 0.7891 - val_loss: 3.6392 - val_mse: 3.6392\n",
            "Epoch 199/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7824 - mse: 0.7824 - val_loss: 3.6342 - val_mse: 3.6342\n",
            "Epoch 200/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7681 - mse: 0.7681 - val_loss: 3.6307 - val_mse: 3.6307\n",
            "Epoch 201/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8029 - mse: 0.8029 - val_loss: 3.6278 - val_mse: 3.6278\n",
            "Epoch 202/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 3.6273 - val_mse: 3.6273\n",
            "Epoch 203/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7929 - mse: 0.7929 - val_loss: 3.6253 - val_mse: 3.6253\n",
            "Epoch 204/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7885 - mse: 0.7885 - val_loss: 3.6204 - val_mse: 3.6204\n",
            "Epoch 205/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7855 - mse: 0.7855 - val_loss: 3.6171 - val_mse: 3.6171\n",
            "Epoch 206/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7817 - mse: 0.7817 - val_loss: 3.6137 - val_mse: 3.6137\n",
            "Epoch 207/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7830 - mse: 0.7830 - val_loss: 3.6132 - val_mse: 3.6132\n",
            "Epoch 208/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7865 - mse: 0.7865 - val_loss: 3.6079 - val_mse: 3.6079\n",
            "Epoch 209/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7953 - mse: 0.7953 - val_loss: 3.6010 - val_mse: 3.6010\n",
            "Epoch 210/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7735 - mse: 0.7735 - val_loss: 3.5955 - val_mse: 3.5955\n",
            "Epoch 211/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7679 - mse: 0.7679 - val_loss: 3.5936 - val_mse: 3.5936\n",
            "Epoch 212/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7597 - mse: 0.7597 - val_loss: 3.5898 - val_mse: 3.5898\n",
            "Epoch 213/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7815 - mse: 0.7815 - val_loss: 3.5846 - val_mse: 3.5846\n",
            "Epoch 214/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7698 - mse: 0.7698 - val_loss: 3.5837 - val_mse: 3.5837\n",
            "Epoch 215/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7613 - mse: 0.7613 - val_loss: 3.5827 - val_mse: 3.5827\n",
            "Epoch 216/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7804 - mse: 0.7804 - val_loss: 3.5791 - val_mse: 3.5791\n",
            "Epoch 217/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7727 - mse: 0.7727 - val_loss: 3.5777 - val_mse: 3.5777\n",
            "Epoch 218/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7713 - mse: 0.7713 - val_loss: 3.5769 - val_mse: 3.5769\n",
            "Epoch 219/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7734 - mse: 0.7734 - val_loss: 3.5763 - val_mse: 3.5763\n",
            "Epoch 220/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7660 - mse: 0.7660 - val_loss: 3.5735 - val_mse: 3.5735\n",
            "Epoch 221/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7382 - mse: 0.7382 - val_loss: 3.5743 - val_mse: 3.5743\n",
            "Epoch 222/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 3.5719 - val_mse: 3.5719\n",
            "Epoch 223/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7732 - mse: 0.7732 - val_loss: 3.5721 - val_mse: 3.5721\n",
            "Epoch 224/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7668 - mse: 0.7668 - val_loss: 3.5711 - val_mse: 3.5711\n",
            "Epoch 225/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7586 - mse: 0.7586 - val_loss: 3.5695 - val_mse: 3.5695\n",
            "Epoch 226/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7752 - mse: 0.7752 - val_loss: 3.5690 - val_mse: 3.5690\n",
            "Epoch 227/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7671 - mse: 0.7671 - val_loss: 3.5652 - val_mse: 3.5652\n",
            "Epoch 228/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7672 - mse: 0.7672 - val_loss: 3.5639 - val_mse: 3.5639\n",
            "Epoch 229/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 3.5655 - val_mse: 3.5655\n",
            "Epoch 230/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7862 - mse: 0.7862 - val_loss: 3.5613 - val_mse: 3.5613\n",
            "Epoch 231/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7635 - mse: 0.7635 - val_loss: 3.5603 - val_mse: 3.5603\n",
            "Epoch 232/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7704 - mse: 0.7704 - val_loss: 3.5577 - val_mse: 3.5577\n",
            "Epoch 233/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7902 - mse: 0.7902 - val_loss: 3.5536 - val_mse: 3.5536\n",
            "Epoch 234/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7592 - mse: 0.7592 - val_loss: 3.5494 - val_mse: 3.5494\n",
            "Epoch 235/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7909 - mse: 0.7909 - val_loss: 3.5452 - val_mse: 3.5452\n",
            "Epoch 236/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7366 - mse: 0.7366 - val_loss: 3.5452 - val_mse: 3.5452\n",
            "Epoch 237/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7695 - mse: 0.7695 - val_loss: 3.5441 - val_mse: 3.5441\n",
            "Epoch 238/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7458 - mse: 0.7458 - val_loss: 3.5427 - val_mse: 3.5427\n",
            "Epoch 239/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7515 - mse: 0.7515 - val_loss: 3.5418 - val_mse: 3.5418\n",
            "Epoch 240/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7566 - mse: 0.7566 - val_loss: 3.5398 - val_mse: 3.5398\n",
            "Epoch 241/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7446 - mse: 0.7446 - val_loss: 3.5398 - val_mse: 3.5398\n",
            "Epoch 242/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7707 - mse: 0.7707 - val_loss: 3.5381 - val_mse: 3.5381\n",
            "Epoch 243/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7512 - mse: 0.7512 - val_loss: 3.5339 - val_mse: 3.5339\n",
            "Epoch 244/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7492 - mse: 0.7492 - val_loss: 3.5306 - val_mse: 3.5306\n",
            "Epoch 245/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7408 - mse: 0.7408 - val_loss: 3.5306 - val_mse: 3.5306\n",
            "Epoch 246/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7469 - mse: 0.7469 - val_loss: 3.5304 - val_mse: 3.5304\n",
            "Epoch 247/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7498 - mse: 0.7498 - val_loss: 3.5307 - val_mse: 3.5307\n",
            "Epoch 248/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7410 - mse: 0.7410 - val_loss: 3.5286 - val_mse: 3.5286\n",
            "Epoch 249/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7509 - mse: 0.7509 - val_loss: 3.5285 - val_mse: 3.5285\n",
            "Epoch 250/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7741 - mse: 0.7741 - val_loss: 3.5214 - val_mse: 3.5214\n",
            "Epoch 251/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7634 - mse: 0.7634 - val_loss: 3.5185 - val_mse: 3.5185\n",
            "Epoch 252/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7444 - mse: 0.7444 - val_loss: 3.5168 - val_mse: 3.5168\n",
            "Epoch 253/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7506 - mse: 0.7506 - val_loss: 3.5126 - val_mse: 3.5126\n",
            "Epoch 254/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 3.5099 - val_mse: 3.5099\n",
            "Epoch 255/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 3.5078 - val_mse: 3.5078\n",
            "Epoch 256/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7554 - mse: 0.7554 - val_loss: 3.5050 - val_mse: 3.5050\n",
            "Epoch 257/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7623 - mse: 0.7623 - val_loss: 3.5025 - val_mse: 3.5025\n",
            "Epoch 258/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7354 - mse: 0.7354 - val_loss: 3.5011 - val_mse: 3.5011\n",
            "Epoch 259/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7629 - mse: 0.7629 - val_loss: 3.4959 - val_mse: 3.4959\n",
            "Epoch 260/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7495 - mse: 0.7495 - val_loss: 3.4948 - val_mse: 3.4948\n",
            "Epoch 261/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7326 - mse: 0.7326 - val_loss: 3.4957 - val_mse: 3.4957\n",
            "Epoch 262/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 3.4958 - val_mse: 3.4958\n",
            "Epoch 263/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 3.4944 - val_mse: 3.4944\n",
            "Epoch 264/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7443 - mse: 0.7443 - val_loss: 3.4892 - val_mse: 3.4892\n",
            "Epoch 265/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7398 - mse: 0.7398 - val_loss: 3.4881 - val_mse: 3.4881\n",
            "Epoch 266/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7470 - mse: 0.7470 - val_loss: 3.4863 - val_mse: 3.4863\n",
            "Epoch 267/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7378 - mse: 0.7378 - val_loss: 3.4848 - val_mse: 3.4848\n",
            "Epoch 268/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7392 - mse: 0.7392 - val_loss: 3.4824 - val_mse: 3.4824\n",
            "Epoch 269/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7480 - mse: 0.7480 - val_loss: 3.4837 - val_mse: 3.4837\n",
            "Epoch 270/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7510 - mse: 0.7510 - val_loss: 3.4830 - val_mse: 3.4830\n",
            "Epoch 271/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7510 - mse: 0.7510 - val_loss: 3.4805 - val_mse: 3.4805\n",
            "Epoch 272/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7473 - mse: 0.7473 - val_loss: 3.4791 - val_mse: 3.4791\n",
            "Epoch 273/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 3.4769 - val_mse: 3.4769\n",
            "Epoch 274/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7519 - mse: 0.7519 - val_loss: 3.4738 - val_mse: 3.4738\n",
            "Epoch 275/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7364 - mse: 0.7364 - val_loss: 3.4710 - val_mse: 3.4710\n",
            "Epoch 276/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7331 - mse: 0.7331 - val_loss: 3.4710 - val_mse: 3.4710\n",
            "Epoch 277/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7261 - mse: 0.7261 - val_loss: 3.4718 - val_mse: 3.4718\n",
            "Epoch 278/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7432 - mse: 0.7432 - val_loss: 3.4709 - val_mse: 3.4709\n",
            "Epoch 279/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7435 - mse: 0.7435 - val_loss: 3.4687 - val_mse: 3.4687\n",
            "Epoch 280/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7400 - mse: 0.7400 - val_loss: 3.4682 - val_mse: 3.4682\n",
            "Epoch 281/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7396 - mse: 0.7396 - val_loss: 3.4662 - val_mse: 3.4662\n",
            "Epoch 282/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7338 - mse: 0.7338 - val_loss: 3.4656 - val_mse: 3.4656\n",
            "Epoch 283/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7498 - mse: 0.7498 - val_loss: 3.4627 - val_mse: 3.4627\n",
            "Epoch 284/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7297 - mse: 0.7297 - val_loss: 3.4623 - val_mse: 3.4623\n",
            "Epoch 285/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7272 - mse: 0.7272 - val_loss: 3.4613 - val_mse: 3.4613\n",
            "Epoch 286/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7418 - mse: 0.7418 - val_loss: 3.4611 - val_mse: 3.4611\n",
            "Epoch 287/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7487 - mse: 0.7487 - val_loss: 3.4589 - val_mse: 3.4589\n",
            "Epoch 288/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7252 - mse: 0.7252 - val_loss: 3.4564 - val_mse: 3.4564\n",
            "Epoch 289/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7304 - mse: 0.7304 - val_loss: 3.4523 - val_mse: 3.4523\n",
            "Epoch 290/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7442 - mse: 0.7442 - val_loss: 3.4504 - val_mse: 3.4504\n",
            "Epoch 291/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7206 - mse: 0.7206 - val_loss: 3.4522 - val_mse: 3.4522\n",
            "Epoch 292/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7416 - mse: 0.7416 - val_loss: 3.4503 - val_mse: 3.4503\n",
            "Epoch 293/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7122 - mse: 0.7122 - val_loss: 3.4492 - val_mse: 3.4492\n",
            "Epoch 294/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 3.4489 - val_mse: 3.4489\n",
            "Epoch 295/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7415 - mse: 0.7415 - val_loss: 3.4459 - val_mse: 3.4459\n",
            "Epoch 296/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7395 - mse: 0.7395 - val_loss: 3.4449 - val_mse: 3.4449\n",
            "Epoch 297/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7458 - mse: 0.7458 - val_loss: 3.4427 - val_mse: 3.4427\n",
            "Epoch 298/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7374 - mse: 0.7374 - val_loss: 3.4410 - val_mse: 3.4410\n",
            "Epoch 299/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7100 - mse: 0.7100 - val_loss: 3.4417 - val_mse: 3.4417\n",
            "Epoch 300/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7321 - mse: 0.7321 - val_loss: 3.4409 - val_mse: 3.4409\n",
            "Epoch 301/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7288 - mse: 0.7288 - val_loss: 3.4366 - val_mse: 3.4366\n",
            "Epoch 302/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7398 - mse: 0.7398 - val_loss: 3.4349 - val_mse: 3.4349\n",
            "Epoch 303/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7491 - mse: 0.7491 - val_loss: 3.4313 - val_mse: 3.4313\n",
            "Epoch 304/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7336 - mse: 0.7336 - val_loss: 3.4316 - val_mse: 3.4316\n",
            "Epoch 305/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7087 - mse: 0.7087 - val_loss: 3.4302 - val_mse: 3.4302\n",
            "Epoch 306/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7514 - mse: 0.7514 - val_loss: 3.4290 - val_mse: 3.4290\n",
            "Epoch 307/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7374 - mse: 0.7374 - val_loss: 3.4283 - val_mse: 3.4283\n",
            "Epoch 308/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7154 - mse: 0.7154 - val_loss: 3.4303 - val_mse: 3.4303\n",
            "Epoch 309/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7540 - mse: 0.7540 - val_loss: 3.4285 - val_mse: 3.4285\n",
            "Epoch 310/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7383 - mse: 0.7383 - val_loss: 3.4278 - val_mse: 3.4278\n",
            "Epoch 311/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7452 - mse: 0.7452 - val_loss: 3.4242 - val_mse: 3.4242\n",
            "Epoch 312/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7374 - mse: 0.7374 - val_loss: 3.4221 - val_mse: 3.4221\n",
            "Epoch 313/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7460 - mse: 0.7460 - val_loss: 3.4206 - val_mse: 3.4206\n",
            "Epoch 314/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7413 - mse: 0.7413 - val_loss: 3.4185 - val_mse: 3.4185\n",
            "Epoch 315/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7339 - mse: 0.7339 - val_loss: 3.4179 - val_mse: 3.4179\n",
            "Epoch 316/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7429 - mse: 0.7429 - val_loss: 3.4185 - val_mse: 3.4185\n",
            "Epoch 317/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7158 - mse: 0.7158 - val_loss: 3.4187 - val_mse: 3.4187\n",
            "Epoch 318/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7532 - mse: 0.7532 - val_loss: 3.4198 - val_mse: 3.4198\n",
            "Epoch 319/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7235 - mse: 0.7235 - val_loss: 3.4190 - val_mse: 3.4190\n",
            "Epoch 320/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7363 - mse: 0.7363 - val_loss: 3.4197 - val_mse: 3.4197\n",
            "Epoch 321/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7374 - mse: 0.7374 - val_loss: 3.4198 - val_mse: 3.4198\n",
            "Epoch 322/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7329 - mse: 0.7329 - val_loss: 3.4194 - val_mse: 3.4194\n",
            "Epoch 323/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7108 - mse: 0.7108 - val_loss: 3.4176 - val_mse: 3.4176\n",
            "Epoch 324/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7254 - mse: 0.7254 - val_loss: 3.4159 - val_mse: 3.4159\n",
            "Epoch 325/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7450 - mse: 0.7450 - val_loss: 3.4133 - val_mse: 3.4133\n",
            "Epoch 326/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7511 - mse: 0.7511 - val_loss: 3.4124 - val_mse: 3.4124\n",
            "Epoch 327/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7245 - mse: 0.7245 - val_loss: 3.4112 - val_mse: 3.4112\n",
            "Epoch 328/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7268 - mse: 0.7268 - val_loss: 3.4103 - val_mse: 3.4103\n",
            "Epoch 329/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7288 - mse: 0.7288 - val_loss: 3.4110 - val_mse: 3.4110\n",
            "Epoch 330/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7256 - mse: 0.7256 - val_loss: 3.4093 - val_mse: 3.4093\n",
            "Epoch 331/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7220 - mse: 0.7220 - val_loss: 3.4093 - val_mse: 3.4093\n",
            "Epoch 332/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7331 - mse: 0.7331 - val_loss: 3.4092 - val_mse: 3.4092\n",
            "Epoch 333/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7319 - mse: 0.7319 - val_loss: 3.4073 - val_mse: 3.4073\n",
            "Epoch 334/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7014 - mse: 0.7014 - val_loss: 3.4064 - val_mse: 3.4064\n",
            "Epoch 335/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7295 - mse: 0.7295 - val_loss: 3.4053 - val_mse: 3.4053\n",
            "Epoch 336/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7309 - mse: 0.7309 - val_loss: 3.4041 - val_mse: 3.4041\n",
            "Epoch 337/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7248 - mse: 0.7248 - val_loss: 3.4038 - val_mse: 3.4038\n",
            "Epoch 338/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7127 - mse: 0.7127 - val_loss: 3.4047 - val_mse: 3.4047\n",
            "Epoch 339/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7283 - mse: 0.7283 - val_loss: 3.4037 - val_mse: 3.4037\n",
            "Epoch 340/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7125 - mse: 0.7125 - val_loss: 3.4025 - val_mse: 3.4025\n",
            "Epoch 341/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7214 - mse: 0.7214 - val_loss: 3.4005 - val_mse: 3.4005\n",
            "Epoch 342/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7254 - mse: 0.7254 - val_loss: 3.3994 - val_mse: 3.3994\n",
            "Epoch 343/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7122 - mse: 0.7122 - val_loss: 3.3997 - val_mse: 3.3997\n",
            "Epoch 344/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7330 - mse: 0.7330 - val_loss: 3.4003 - val_mse: 3.4003\n",
            "Epoch 345/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7441 - mse: 0.7441 - val_loss: 3.3990 - val_mse: 3.3990\n",
            "Epoch 346/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7132 - mse: 0.7132 - val_loss: 3.3979 - val_mse: 3.3979\n",
            "Epoch 347/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7187 - mse: 0.7187 - val_loss: 3.3957 - val_mse: 3.3957\n",
            "Epoch 348/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7315 - mse: 0.7315 - val_loss: 3.3941 - val_mse: 3.3941\n",
            "Epoch 349/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7220 - mse: 0.7220 - val_loss: 3.3956 - val_mse: 3.3956\n",
            "Epoch 350/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7144 - mse: 0.7144 - val_loss: 3.3964 - val_mse: 3.3964\n",
            "Epoch 351/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7182 - mse: 0.7182 - val_loss: 3.3953 - val_mse: 3.3953\n",
            "Epoch 352/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7140 - mse: 0.7140 - val_loss: 3.3951 - val_mse: 3.3951\n",
            "Epoch 353/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7276 - mse: 0.7276 - val_loss: 3.3957 - val_mse: 3.3957\n",
            "Epoch 354/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7397 - mse: 0.7397 - val_loss: 3.3959 - val_mse: 3.3959\n",
            "Epoch 355/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7241 - mse: 0.7241 - val_loss: 3.3944 - val_mse: 3.3944\n",
            "Epoch 356/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7208 - mse: 0.7208 - val_loss: 3.3935 - val_mse: 3.3935\n",
            "Epoch 357/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7317 - mse: 0.7317 - val_loss: 3.3918 - val_mse: 3.3918\n",
            "Epoch 358/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7228 - mse: 0.7228 - val_loss: 3.3904 - val_mse: 3.3904\n",
            "Epoch 359/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7141 - mse: 0.7141 - val_loss: 3.3893 - val_mse: 3.3893\n",
            "Epoch 360/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7252 - mse: 0.7252 - val_loss: 3.3872 - val_mse: 3.3872\n",
            "Epoch 361/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7129 - mse: 0.7129 - val_loss: 3.3866 - val_mse: 3.3866\n",
            "Epoch 362/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7197 - mse: 0.7197 - val_loss: 3.3878 - val_mse: 3.3878\n",
            "Epoch 363/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7085 - mse: 0.7085 - val_loss: 3.3880 - val_mse: 3.3880\n",
            "Epoch 364/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7140 - mse: 0.7140 - val_loss: 3.3870 - val_mse: 3.3870\n",
            "Epoch 365/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7176 - mse: 0.7176 - val_loss: 3.3874 - val_mse: 3.3874\n",
            "Epoch 366/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7095 - mse: 0.7095 - val_loss: 3.3884 - val_mse: 3.3884\n",
            "Epoch 367/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7184 - mse: 0.7184 - val_loss: 3.3874 - val_mse: 3.3874\n",
            "Epoch 368/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7125 - mse: 0.7125 - val_loss: 3.3856 - val_mse: 3.3856\n",
            "Epoch 369/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7203 - mse: 0.7203 - val_loss: 3.3849 - val_mse: 3.3849\n",
            "Epoch 370/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7345 - mse: 0.7345 - val_loss: 3.3803 - val_mse: 3.3803\n",
            "Epoch 371/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7180 - mse: 0.7180 - val_loss: 3.3813 - val_mse: 3.3813\n",
            "Epoch 372/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7350 - mse: 0.7350 - val_loss: 3.3810 - val_mse: 3.3810\n",
            "Epoch 373/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7129 - mse: 0.7129 - val_loss: 3.3796 - val_mse: 3.3796\n",
            "Epoch 374/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7247 - mse: 0.7247 - val_loss: 3.3793 - val_mse: 3.3793\n",
            "Epoch 375/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7158 - mse: 0.7158 - val_loss: 3.3776 - val_mse: 3.3776\n",
            "Epoch 376/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7337 - mse: 0.7337 - val_loss: 3.3763 - val_mse: 3.3763\n",
            "Epoch 377/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7299 - mse: 0.7299 - val_loss: 3.3760 - val_mse: 3.3760\n",
            "Epoch 378/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7164 - mse: 0.7164 - val_loss: 3.3755 - val_mse: 3.3755\n",
            "Epoch 379/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7212 - mse: 0.7212 - val_loss: 3.3734 - val_mse: 3.3734\n",
            "Epoch 380/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7105 - mse: 0.7105 - val_loss: 3.3734 - val_mse: 3.3734\n",
            "Epoch 381/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7408 - mse: 0.7408 - val_loss: 3.3739 - val_mse: 3.3739\n",
            "Epoch 382/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7149 - mse: 0.7149 - val_loss: 3.3734 - val_mse: 3.3734\n",
            "Epoch 383/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7324 - mse: 0.7324 - val_loss: 3.3730 - val_mse: 3.3730\n",
            "Epoch 384/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7387 - mse: 0.7387 - val_loss: 3.3701 - val_mse: 3.3701\n",
            "Epoch 385/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7033 - mse: 0.7033 - val_loss: 3.3682 - val_mse: 3.3682\n",
            "Epoch 386/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7165 - mse: 0.7165 - val_loss: 3.3688 - val_mse: 3.3688\n",
            "Epoch 387/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7075 - mse: 0.7075 - val_loss: 3.3688 - val_mse: 3.3688\n",
            "Epoch 388/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7127 - mse: 0.7127 - val_loss: 3.3687 - val_mse: 3.3687\n",
            "Epoch 389/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7189 - mse: 0.7189 - val_loss: 3.3692 - val_mse: 3.3692\n",
            "Epoch 390/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7279 - mse: 0.7279 - val_loss: 3.3707 - val_mse: 3.3707\n",
            "Epoch 391/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7332 - mse: 0.7332 - val_loss: 3.3704 - val_mse: 3.3704\n",
            "Epoch 392/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7112 - mse: 0.7112 - val_loss: 3.3725 - val_mse: 3.3725\n",
            "Epoch 393/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7162 - mse: 0.7162 - val_loss: 3.3718 - val_mse: 3.3718\n",
            "Epoch 394/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7163 - mse: 0.7163 - val_loss: 3.3719 - val_mse: 3.3719\n",
            "Epoch 395/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6947 - mse: 0.6947 - val_loss: 3.3709 - val_mse: 3.3709\n",
            "Epoch 396/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7140 - mse: 0.7140 - val_loss: 3.3723 - val_mse: 3.3723\n",
            "Epoch 397/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7004 - mse: 0.7004 - val_loss: 3.3714 - val_mse: 3.3714\n",
            "Epoch 398/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7226 - mse: 0.7226 - val_loss: 3.3712 - val_mse: 3.3712\n",
            "Epoch 399/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7229 - mse: 0.7229 - val_loss: 3.3709 - val_mse: 3.3709\n",
            "Epoch 400/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7263 - mse: 0.7263 - val_loss: 3.3666 - val_mse: 3.3666\n",
            "Epoch 401/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7293 - mse: 0.7293 - val_loss: 3.3649 - val_mse: 3.3649\n",
            "Epoch 402/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7062 - mse: 0.7062 - val_loss: 3.3627 - val_mse: 3.3627\n",
            "Epoch 403/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7053 - mse: 0.7053 - val_loss: 3.3602 - val_mse: 3.3602\n",
            "Epoch 404/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7102 - mse: 0.7102 - val_loss: 3.3585 - val_mse: 3.3585\n",
            "Epoch 405/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7056 - mse: 0.7056 - val_loss: 3.3571 - val_mse: 3.3571\n",
            "Epoch 406/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7193 - mse: 0.7193 - val_loss: 3.3564 - val_mse: 3.3564\n",
            "Epoch 407/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7312 - mse: 0.7312 - val_loss: 3.3542 - val_mse: 3.3542\n",
            "Epoch 408/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7209 - mse: 0.7209 - val_loss: 3.3542 - val_mse: 3.3542\n",
            "Epoch 409/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7031 - mse: 0.7031 - val_loss: 3.3529 - val_mse: 3.3529\n",
            "Epoch 410/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7252 - mse: 0.7252 - val_loss: 3.3525 - val_mse: 3.3525\n",
            "Epoch 411/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7097 - mse: 0.7097 - val_loss: 3.3511 - val_mse: 3.3511\n",
            "Epoch 412/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7118 - mse: 0.7118 - val_loss: 3.3504 - val_mse: 3.3504\n",
            "Epoch 413/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7246 - mse: 0.7246 - val_loss: 3.3498 - val_mse: 3.3498\n",
            "Epoch 414/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7076 - mse: 0.7076 - val_loss: 3.3483 - val_mse: 3.3483\n",
            "Epoch 415/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7069 - mse: 0.7069 - val_loss: 3.3482 - val_mse: 3.3482\n",
            "Epoch 416/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6840 - mse: 0.6840 - val_loss: 3.3479 - val_mse: 3.3479\n",
            "Epoch 417/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6965 - mse: 0.6965 - val_loss: 3.3470 - val_mse: 3.3470\n",
            "Epoch 418/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7327 - mse: 0.7327 - val_loss: 3.3460 - val_mse: 3.3460\n",
            "Epoch 419/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7057 - mse: 0.7057 - val_loss: 3.3465 - val_mse: 3.3465\n",
            "Epoch 420/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7144 - mse: 0.7144 - val_loss: 3.3449 - val_mse: 3.3449\n",
            "Epoch 421/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7147 - mse: 0.7147 - val_loss: 3.3448 - val_mse: 3.3448\n",
            "Epoch 422/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7060 - mse: 0.7060 - val_loss: 3.3438 - val_mse: 3.3438\n",
            "Epoch 423/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7112 - mse: 0.7112 - val_loss: 3.3445 - val_mse: 3.3445\n",
            "Epoch 424/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7015 - mse: 0.7015 - val_loss: 3.3457 - val_mse: 3.3457\n",
            "Epoch 425/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7047 - mse: 0.7047 - val_loss: 3.3455 - val_mse: 3.3455\n",
            "Epoch 426/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7231 - mse: 0.7231 - val_loss: 3.3459 - val_mse: 3.3459\n",
            "Epoch 427/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6985 - mse: 0.6985 - val_loss: 3.3447 - val_mse: 3.3447\n",
            "Epoch 428/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7047 - mse: 0.7047 - val_loss: 3.3437 - val_mse: 3.3437\n",
            "Epoch 429/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7072 - mse: 0.7072 - val_loss: 3.3434 - val_mse: 3.3434\n",
            "Epoch 430/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7365 - mse: 0.7365 - val_loss: 3.3440 - val_mse: 3.3440\n",
            "Epoch 431/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7025 - mse: 0.7025 - val_loss: 3.3452 - val_mse: 3.3452\n",
            "Epoch 432/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7179 - mse: 0.7179 - val_loss: 3.3451 - val_mse: 3.3451\n",
            "Epoch 433/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7036 - mse: 0.7036 - val_loss: 3.3466 - val_mse: 3.3466\n",
            "Epoch 434/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7002 - mse: 0.7002 - val_loss: 3.3462 - val_mse: 3.3462\n",
            "Epoch 435/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6957 - mse: 0.6957 - val_loss: 3.3464 - val_mse: 3.3464\n",
            "Epoch 436/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6951 - mse: 0.6951 - val_loss: 3.3471 - val_mse: 3.3471\n",
            "Epoch 437/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7181 - mse: 0.7181 - val_loss: 3.3454 - val_mse: 3.3454\n",
            "Epoch 438/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7316 - mse: 0.7316 - val_loss: 3.3449 - val_mse: 3.3449\n",
            "Epoch 439/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7144 - mse: 0.7144 - val_loss: 3.3446 - val_mse: 3.3446\n",
            "Epoch 440/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7009 - mse: 0.7009 - val_loss: 3.3447 - val_mse: 3.3447\n",
            "Epoch 441/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6980 - mse: 0.6980 - val_loss: 3.3441 - val_mse: 3.3441\n",
            "Epoch 442/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6983 - mse: 0.6983 - val_loss: 3.3457 - val_mse: 3.3457\n",
            "Epoch 443/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6992 - mse: 0.6992 - val_loss: 3.3454 - val_mse: 3.3454\n",
            "Epoch 444/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7040 - mse: 0.7040 - val_loss: 3.3453 - val_mse: 3.3453\n",
            "Epoch 445/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7000 - mse: 0.7000 - val_loss: 3.3447 - val_mse: 3.3447\n",
            "Epoch 446/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7231 - mse: 0.7231 - val_loss: 3.3448 - val_mse: 3.3448\n",
            "Epoch 447/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7205 - mse: 0.7205 - val_loss: 3.3445 - val_mse: 3.3445\n",
            "Epoch 448/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7054 - mse: 0.7054 - val_loss: 3.3445 - val_mse: 3.3445\n",
            "Epoch 449/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7095 - mse: 0.7095 - val_loss: 3.3457 - val_mse: 3.3457\n",
            "Epoch 450/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7266 - mse: 0.7266 - val_loss: 3.3433 - val_mse: 3.3433\n",
            "Epoch 451/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7246 - mse: 0.7246 - val_loss: 3.3421 - val_mse: 3.3421\n",
            "Epoch 452/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6990 - mse: 0.6990 - val_loss: 3.3425 - val_mse: 3.3425\n",
            "Epoch 453/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6957 - mse: 0.6957 - val_loss: 3.3413 - val_mse: 3.3413\n",
            "Epoch 454/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7057 - mse: 0.7057 - val_loss: 3.3425 - val_mse: 3.3425\n",
            "Epoch 455/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7088 - mse: 0.7088 - val_loss: 3.3432 - val_mse: 3.3432\n",
            "Epoch 456/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7015 - mse: 0.7015 - val_loss: 3.3430 - val_mse: 3.3430\n",
            "Epoch 457/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7045 - mse: 0.7045 - val_loss: 3.3444 - val_mse: 3.3444\n",
            "Epoch 458/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6843 - mse: 0.6843 - val_loss: 3.3449 - val_mse: 3.3449\n",
            "Epoch 459/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7026 - mse: 0.7026 - val_loss: 3.3449 - val_mse: 3.3449\n",
            "Epoch 460/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6862 - mse: 0.6862 - val_loss: 3.3448 - val_mse: 3.3448\n",
            "Epoch 461/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7138 - mse: 0.7138 - val_loss: 3.3454 - val_mse: 3.3454\n",
            "Epoch 462/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6954 - mse: 0.6954 - val_loss: 3.3447 - val_mse: 3.3447\n",
            "Epoch 463/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7287 - mse: 0.7287 - val_loss: 3.3440 - val_mse: 3.3440\n",
            "Epoch 464/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7019 - mse: 0.7019 - val_loss: 3.3442 - val_mse: 3.3442\n",
            "Epoch 465/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6992 - mse: 0.6992 - val_loss: 3.3442 - val_mse: 3.3442\n",
            "Epoch 466/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7021 - mse: 0.7021 - val_loss: 3.3447 - val_mse: 3.3447\n",
            "Epoch 467/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7102 - mse: 0.7102 - val_loss: 3.3447 - val_mse: 3.3447\n",
            "Epoch 468/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7003 - mse: 0.7003 - val_loss: 3.3463 - val_mse: 3.3463\n",
            "Epoch 469/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7104 - mse: 0.7104 - val_loss: 3.3477 - val_mse: 3.3477\n",
            "Epoch 470/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6995 - mse: 0.6995 - val_loss: 3.3466 - val_mse: 3.3466\n",
            "Epoch 471/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7174 - mse: 0.7174 - val_loss: 3.3473 - val_mse: 3.3473\n",
            "Epoch 472/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7085 - mse: 0.7085 - val_loss: 3.3484 - val_mse: 3.3484\n",
            "Epoch 473/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7144 - mse: 0.7144 - val_loss: 3.3468 - val_mse: 3.3468\n",
            "Epoch 474/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7062 - mse: 0.7062 - val_loss: 3.3452 - val_mse: 3.3452\n",
            "Epoch 475/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7062 - mse: 0.7062 - val_loss: 3.3448 - val_mse: 3.3448\n",
            "Epoch 476/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7004 - mse: 0.7004 - val_loss: 3.3424 - val_mse: 3.3424\n",
            "Epoch 477/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6926 - mse: 0.6926 - val_loss: 3.3439 - val_mse: 3.3439\n",
            "Epoch 478/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7051 - mse: 0.7051 - val_loss: 3.3425 - val_mse: 3.3425\n",
            "Epoch 479/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6924 - mse: 0.6924 - val_loss: 3.3418 - val_mse: 3.3418\n",
            "Epoch 480/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7175 - mse: 0.7175 - val_loss: 3.3414 - val_mse: 3.3414\n",
            "Epoch 481/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6892 - mse: 0.6892 - val_loss: 3.3415 - val_mse: 3.3415\n",
            "Epoch 482/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6862 - mse: 0.6862 - val_loss: 3.3398 - val_mse: 3.3398\n",
            "Epoch 483/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7092 - mse: 0.7092 - val_loss: 3.3385 - val_mse: 3.3385\n",
            "Epoch 484/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7059 - mse: 0.7059 - val_loss: 3.3377 - val_mse: 3.3377\n",
            "Epoch 485/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6970 - mse: 0.6970 - val_loss: 3.3382 - val_mse: 3.3382\n",
            "Epoch 486/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7172 - mse: 0.7172 - val_loss: 3.3367 - val_mse: 3.3367\n",
            "Epoch 487/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7016 - mse: 0.7016 - val_loss: 3.3362 - val_mse: 3.3362\n",
            "Epoch 488/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7064 - mse: 0.7064 - val_loss: 3.3351 - val_mse: 3.3351\n",
            "Epoch 489/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7048 - mse: 0.7048 - val_loss: 3.3349 - val_mse: 3.3349\n",
            "Epoch 490/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6975 - mse: 0.6975 - val_loss: 3.3353 - val_mse: 3.3353\n",
            "Epoch 491/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7137 - mse: 0.7137 - val_loss: 3.3333 - val_mse: 3.3333\n",
            "Epoch 492/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7104 - mse: 0.7104 - val_loss: 3.3330 - val_mse: 3.3330\n",
            "Epoch 493/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7013 - mse: 0.7013 - val_loss: 3.3317 - val_mse: 3.3317\n",
            "Epoch 494/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7107 - mse: 0.7107 - val_loss: 3.3320 - val_mse: 3.3320\n",
            "Epoch 495/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7267 - mse: 0.7267 - val_loss: 3.3327 - val_mse: 3.3327\n",
            "Epoch 496/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7077 - mse: 0.7077 - val_loss: 3.3298 - val_mse: 3.3298\n",
            "Epoch 497/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7160 - mse: 0.7160 - val_loss: 3.3285 - val_mse: 3.3285\n",
            "Epoch 498/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6981 - mse: 0.6981 - val_loss: 3.3292 - val_mse: 3.3292\n",
            "Epoch 499/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6890 - mse: 0.6890 - val_loss: 3.3290 - val_mse: 3.3290\n",
            "Epoch 500/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6991 - mse: 0.6991 - val_loss: 3.3286 - val_mse: 3.3286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FsR2_UelFOs0",
        "outputId": "8594a818-fea6-4be4-cc64-55108fef79de"
      },
      "source": [
        "plt.plot(history.history['val_mse'],label='Validation MSE')\n",
        "plt.plot(history.history['mse'],label='Training MSE')\n",
        "plt.legend()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f899ed33b10>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3epx_z9FU31",
        "outputId": "d62b48c8-6437-43ee-ae18-3229ac0efb46"
      },
      "source": [
        "prediction = model.predict(np.hstack((validation_x,validation_x2)))\n",
        "calculate_error_rmse(pd.DataFrame(prediction).mul(scaler_y), validation_volatility)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022707300434842134"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3sRfV8SHJBE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}